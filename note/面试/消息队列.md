### 1. Kafka为什么比RocketMQ的吞吐量高

Kafka的生产者采用的是异步发送消息机制，当发送一条消息时，消息并没有发送到Broker而是缓存起来，然后直接向业务返回成功，当缓存的消息达到一定数量时在批量发送给Broker，这种做法减少了网络IO，从而提高了消息发送的吞吐量，但是如果消息生产者宕机，会导致消息丢失，业务出错，所以理论上Kafka利用此机制提高了性能却降低了可靠性。

### 2. Kafka的Pull和Push分别有什么优缺点

1.  pull表示消费者主动拉取，可以批量拉取，也可以单条拉取，所以pull可以由消费者自己控制，根据自己的消费处理能力来进行控制，但是消费者不能技师知道是否有消息，可能会拉到的消息为空
2.  push表示Broker主动给消费者推送消息，所有肯定是有消息时才会推送，但是消费者不能按自己的能力来消费消息，推过来多少消息，消费者就得消费多少消息，所以可能会造成网络拥塞，消费者压力大等问题。

pull模式：

1.  根据Consumer的消费能力进行数据拉取，可以控制速率
2.  可以批量拉取，也可以单条拉取
3.  可以设置不同的提交方式，实现不同的传输语义

缺点：如果kafka没有数据，会导致consumer空循环，消耗资源

解决：通过参数配置，consumer拉取数据为空或者没有达到一定数量是进行阻塞



push模式：不会导致consumer循环等待

缺点：速率固定，忽略了consumer的消费能力，可能导致拒绝服务或网络拥塞等情况

### 3. Kafka，ActiveMQ，RabbitMQ，RocketMQ对比

ActiveMQ：JVM规范，支持事务，支持XA协议，没有生产大规模支撑场景，官方维护越来越少

RabbitMQ：erlang语言开发，性能好，高并发，支持多种语言，社区，文档访问有优势，erlang语言不利于java二次开发，依赖开源社区的维护和升级，需要学习AMQP协议，学习成本相对较高

以上吞吐量单机都在万级

Kafka：高性能，高可用，生产环境有大规模使用场景，单机容量有限（超过64个分区响应明显变长），社区更新慢

吞吐量单机百万

RocketMQ：java实现，方便二次开发，设计参考了kafka，高可用，高可靠，社区活跃度一般，支持语言较少

吞吐量单机十万

### 4. Kafka消息高可靠解决方案

消息发送：

-   ack：0，重试；1，lead写入成功就返回了；all/-1，等待ISR同步完再返回
-   unclean.leader.election.enable:false，禁止选举ISR意外的follower为leader
-   tries > 1，重试次数
-   min.insync.replicas > 1：同步副本数，没满足该值前，不提供读写服务，写操作会异常

消费：

-   手工提交offset
-   broker：减小刷盘间隙
-   事务消息

 ### 5. Kafka高性能高吞吐的原因

1.  磁盘顺序读写：保证了消息的堆积

    -   顺序读写，磁盘会预读，预读即在读取的起始地址连续读取多个页面，主要时间花费在了传输时间，而这个时间两种读写可以认为是一样的。
    -   随机读写，因为数据没有在一起了，将预读浪费掉了。需要多次寻道和旋转延迟，而这个时间可能是传输时间的许多倍

2.  零拷贝：避免CPU将数据从一块存储拷贝到另一块存储的技术

    -   传统的数据复制：

        1.  读取磁盘文件数据到内核缓冲区
        2.  将内核缓冲区的数据copy到用户缓冲区
        3.  将用户缓冲区的数据copy到socket的发送缓冲区
        4.  将socket发送缓冲区的数据发送到网卡，进行传输

    -   零拷贝：

        磁盘文件  -> 内核空间读取缓冲区 -> 网卡接口  -> 消费者进程

3.  分区分段+索引

    Kafka的message消息实际上是分布式存储在一个个小的segment中的，每次文件操作也是直接操作segment。为了进一步的查询优化，kafka又默认为分段后的数据文件简历了索引文件，就是文件系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。

4.  批量压缩：多条消息一起压缩，降低带宽

5.  批量读写

6.  直接操作page cache，而不是JVM，避免GC耗时及对象创建耗时，且读写速度更高，进程重启，缓存也不会丢失

### 6. Kafka消息丢失的场景以及解决方案

1.  消息发送：

    ```
    1. ack = 0，不重试
    producer发送消息完，不管结果，如果发送失败也就丢失了
    
    2. ack = 1，leader crash
    producer发送完消息，只等待lead写入成功就返回了，leader crash了，这时follower没来得及同步，消息丢失
    
    3. unclear.leader.election.enable 配置true
    允许选举ISR以外的副本作为leader，会导致数据丢失，默认为false。producer发送异步消息完，只等待lead写入成功就返回了，leader crash了，这时ISR中没有follower，leader从OSR中选举，因为OSR中本来落后于leader造成消息丢失。
    
    解决方案：
    1. 配置：ack = all / -1，tries > 1，unclear.leader.election.enable: false
    producer发送消息完，等待follower同步完再返回，如果异常则重试，副本的数量可能影响吞吐量
    不允许选举ISR以外的副本作为leader
    
    2. 配置：min.insync.replicas > 1
    副本指定必须确认写操作成功的最小副本数量，如果不能满足这个最小值，则生产者将引发一个异常(要么是NotEnoughReplicas,要么是NotEnoughReplicasAfterAppend)。
    
    min.insync.replicas和ack更大的持久性保证，确保如果大多数副本没有收到写操作，则生产者将引发异常。
    
    3. 失败的offset单独记录
    producer发送消息，会自动重试，遇到不可恢复异常会抛出，这时可以捕获异常记录到数据库或缓存，进行单独处理。
    ```

2.  消费

    ```
    先commit再处理消息，如果在处理消息的时候异常了，但是offset已经提交了，这条消息对于该消费者来说就是丢失了，再也不会消费到了。
    ```

3.  broker刷盘

    减小刷盘时间间隔


### 7. Kafka中高性能的原因

Kafka不基于内存，而是硬盘存储，因此消息堆积能力更强

顺序写：利用磁盘的顺序访问速度可以接近内存，Kafka的消息都是append操作，partition是有序的，节省了磁盘的寻道时间，同时通过批量操作，节省写入次数，partition物理上分为多个segment存储，方便删除。

传统：

-   读取磁盘文件到内核缓冲区
-   将内核缓冲区的数据copy到用户缓冲区
-   将用户缓冲区的数据copy到socket的发送缓冲区
-   将socket发送缓冲区的数据发送到网卡，进行传输

零拷贝：

-   直接将内核缓冲区的数据发送到网卡传输
-   使用的是操作系统的指令支持

Kafka不太依赖JVM，主要理由操作系统的pageCache，如果生产消费速率相当，则直接用pageCache交换数据，不需要经过磁盘IO。

### 8. Kafka中ZK的作用

/brokers/ids：临时节点，保存所有broker节点信息，存储broker的物理地址，版本信息，启动时间等，节点名称为brokerID，broker定时发送心跳到zk，如果断开则该brokerID会被删除

/brokers/topics：临时节点，节点保存broker节点下所有的topic信息，每一个topic节点下包含一个固定的partitions节点，partitions的子节点就是topic的分区，每个分区下保存一个state节点，保存着当前leader分区和ISR的brokerID，state节点由leader创建，若leader宕机该节点会本删除，直到有新的leader选举产生，重新生成state节点

/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]：维护消费者和分区的注册关系

/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]：分区消息的消费进度offset



client通过topic找到topic树下的state节点，获取leader的brokerID，到brokerID树中找到broker的物理地址，但是client不会直连zk，而是通过配置的broker获取到zk中的信息。

### 9. 如何保证消息消费的幂等性

消费者重复消费问题。

所有MQ产品并没有提供主动解决幂等性的机制，需要消费者自行控制。

RocketMQ：给每个消息分配了MessageID，这个MessageID。这个MessageID可以作为消费者判断幂等的依据。这种方式不太建议

最好的方式就是自己带一个有业务标识的ID，来进行幂等判断。

统一ID分配。

### 10. 使用MQ如何保证分布式事务的最终一致性

分布式事务：业务相关的多个操作，保证他们同时成功或者同时失败

最终一致性：对应的就是强一致性

MQ中要保护事务的最终一致性，就要做到以下两点

1.  生产者要保证100%的消息传递
2.  消费者端要保证幂等消费

分布式MQ的三种语义：

at least once：至少消费一次（失败保证重试）

at most once：发送完不管是否消费

exactly once：RocketMQ并不能保证exactly once，商业版本中提供了exactly once的实现机制

​		kafka：在最新版本的源码中，提供了exactly once的demo

​		RabbitMQ：erlang天生成为了一种屏障

### 11. 如何进行MQ产品选型

-   Kafka：
    -   优点：吞吐量非常大，性能非常好，集群高可用
    -   缺点：会丢数据，功能比较单一
    -   使用场景：日志分析，大数据采集
-   RabbitMQ：
    -   优点：消息可靠性高，功能全面
    -   缺点：吞吐量比较低，消息积累会严重影响性能，erlang语言不好定制。
    -   使用场景：小规模场景
-   RocketMQ：
    -   优点：高吞吐，高性能，高可用，功能全面
    
    -   缺点：开源版功能不如云上商业版本，官方文档和周边生态不够成熟，客户端只支持java
    
    -   使用场景：几乎全场景
    
    -   # 1. 微服务架构
    
        ![](https://secure2.wostatic.cn/static/uH2Deq2UnbYVWKFkskASsZ/微服务架构 (1).png)
    
        # 2. 缓存和异步消息
    
        Redis：
    
        -   单线程，NIO，异步事件处理
    
        消息中间件（ActiveMQ，RabbieMQ，RocketMQ，Kafka）
    
        -   削峰，异步，解耦
        -   重复消费：幂等，唯一键
        -   丢消息：acks = all
        -   消息积压：
            -   增加分区，增加消费者组
        -   顺序消费：
            -   消费者维护偏移量
    
        # 3. 分布式锁
    
        -   基于Redis：Redisson
    
            -   SETNX
            -   过期时间
            -   看门狗，自动续期
            -   加锁解锁原子操作
            -   lua脚本
    
            ![img](https://secure2.wostatic.cn/static/8kuDwKy1fermHCD1EzyG1S/Redisson%E6%B5%81%E7%A8%8B.png)
    
        -   基于Zookeeper
    
            -   watcher
                -   临时有序节点，按顺序监听
                -   惊群效应
            -   myid，ZXID
                -   Leader选举，1. ZXID最大，2. myid最大
            -   两阶段
                1.  Propose：leader第一阶段，写入日志文件，同步到follower
                2.  Commit：leader收到超过半数ack，执行commit
    
        ![img](https://secure2.wostatic.cn/static/9r8sj8KbJij6SRqQrxepDN/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.png)
    
        # 4. 分布式事务
    
        # 5. 分布式session
    
        # 6. 并发
    
        ## 7. Zookeeper
    
        ## 1. 什么是死锁？如何排查死锁？
    
        ```
        多个线程互相持有资源，并且等待对方资源进行释放
        
        排查：Jstack pid
        ```
    
        ## 2. 如何保证多线程执行的顺序？
    
        ```
        join
        ```
    
        # 
    
        # 1. 集群中的机器角色都有哪些
    
        ```
        - Leader：负责读和写，选举投票权
        - Follower：负责读，选举投票权
        - Ovserver：负责读，没有任何的投票权
        ```

### 12. 如何保证消息的高效读写

零拷贝：Kafka和RocketMQ都是通过零拷贝技术来优化文件读写

传统拷贝方式：需要对文件在内存中进行四次拷贝

![传统拷贝方式](%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.assets/%E4%BC%A0%E7%BB%9F%E6%8B%B7%E8%B4%9D%E6%96%B9%E5%BC%8F.png)

零拷贝：有两种方式，mmap和transfile

![零拷贝](%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.assets/%E9%9B%B6%E6%8B%B7%E8%B4%9D-1636353317363.png)

Java当中对零拷贝进行了封装，MMAP方式通过MappedByteBuffer对象进行操作，而transfile通过fileChannel来进行操作，

Mmap适合比较小的文件，通常文件大小不要超过1.5G~2G之间

Transfile没有文件大小限制

RocketMQ当中使用Mmap方式来对它的文件进行读写，commitlog，1G

在Kafka当中，他的index日志文件也是通过mmap的方式来读写的，在其他日志文件当中，并没有使用零拷贝的方式

Kafka使用transfile方式将硬盘数据加载到网卡

### 13. 如何保证消息的顺序

全局有序和局部有序：MQ只需要保证局部有序，不需要保证全局有序。

**生产者把一组有序的消息放到同一个队列当中，而消费者一次消费整个队列当中的消息。**

RocketMQ中有完整的设计，但是在RabbitMQ和Kafka中，并没有完整的设计，需要自己实现

RabbitMQ：要保证目标Exchange只对应一个队列，并且一个队列只对应一个消费者

Kafka：生产者通过定制partition分配规则，将消息分配到同一个partition。topic下只对应一个消费者。

### 14. 如何保证消息不丢失

1.  哪些环节回造成消息丢失？

    ![MQ消息可能丢失场景](../../../../../../Downloads/MQ%E6%B6%88%E6%81%AF%E5%8F%AF%E8%83%BD%E4%B8%A2%E5%A4%B1%E5%9C%BA%E6%99%AF.png)

2.  怎么去防止消息丢失？

    1.  生产者发送消息不丢失

        Kafka：消息发送+回调（producer发送消息，注册回调函数）

        RocketMQ：

         	1. 消息发送+回调；
         	2. 事务消息

        ![RoctetMQ分布式事务](%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.assets/RoctetMQ%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1.png)

        RabbitMQ：

         1.    消息发送+回调

         2.    手动事务：

               -   channel.txSelect()开启事务

               -   channel.txCommit()提交事务

               -   channel.txRollback()回滚事务

                   这种方式对channel是会产生阻塞的，造成吞吐量下降

        	3. Publisher Confirm：

            整个处理流程跟RocketMQ的事务消息，基本是一样的。

    2.  MQ主从消息同步不丢失

        -   RocketMQ：

            1.  普通集群中，同步同步，异步同步。

                异步同步效率更高，但是有丢消息的风险，同步同步就不会丢消息。

            2.  Dledger集群-两阶段提交：

        -   RabbitMQ：

            普通集群：消息是分散存储的，节点之间不会主动进行消息同步，是有可能丢失消息的。

            镜像模式：镜像集群会在节点之间主动进行数据同步，这样数据安全性得到提高。

        -   Kafka：通常都是用在允许少量消息丢失的场景

    3.  MQ消息存盘不丢失

        RocketMQ：同步刷盘，异步刷盘：异步刷盘效率更高，但是有可能丢失消息。同步刷盘消息安全性更高，但是效率会更低

        RabbitMQ：将队列配置成持久化队列。新增的Quorum类型的队列，会采用Raft协议来进行消息同步。

    4.  MQ消费者消费消息不丢失

        RocketMQ：使用默认的方式消费就行，不要采用异步方式

        RabbitMQ：autoCommit -> 手动提交offset

        Kafka：手动提交offset

### 15. RabbitMQ的镜像队列原理

![RabbitMQ镜像队列](%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.assets/RabbitMQ%E9%95%9C%E5%83%8F%E9%98%9F%E5%88%97.png)

GM负责消息的广播，所有的GM组成gm_group，行程链表结构，负责监听相邻节点的状态，以及传递消息到相邻节点，master的GM收到消息时代表消息同步完成

mirro_queue_master/slave负责消息的处理，操作blockingQueue，Queue负责AMQP协议（commit，rollback，ack等）

master处理读写

### 16. MQ有什么用？有哪些具体的使用场景

MQ：MessageQueue，消息队列。队列是一种FIFO先进先出的数据结构。消息由生产者发送到MQ进行排队，然后由消费者对消息进行处理。QQ，微信就是典型的MQ场景。

MQ的作用主要有三个方面：

1.  异步

    例子：快递。快递员->菜鸟驿站<-客户

    作用：异步能提高系统的响应速度和吞吐量

2.  解耦

    例子：《Thinking in java》 -> 编辑社

    作用：服务之间进行解耦，可以减少服务之间的影响，提高系统的稳定性和可扩展性

    解耦之后可以实现数据分发，生产者发送一个消息后，可以由多个消费者来处理

3.  削峰

    例子：长江涨水 -> 三峡大坝

    作用：以稳定的系统资源应对突发的流量冲击

MQ的缺点：

1.  系统可用性降低：一旦MQ宕机，整个业务就会产生影响
2.  系统的复杂度提高：引入MQ之后，数据链路就会变得复杂，如何保证消息不丢失？消息不会重复调用？怎么保证消息的顺序性？
3.  数据一致性：A系统发消息，需要由B，C两个系统一同处理，如果B系统处理成功，C系统处理失败，这就会造成数据一致性问题。

### 17. RabbitMQ的死信队列，延迟队列原理

死信消息：

1.  消息被消费方否定确认，使用`channel.basicNack`或`channel.basicReject`，并且此时`requeue`属性被设置为`false`。
2.  消息在队列的存活时间超过设置的TTL时间。
3.  消息队列的消息数量已经超过最大队列长度。

那么该消息将成为死信队列，如果配置了死信队列信息，那么该消息将会被丢进死信队列中，如果没有配置，则该消息将会被丢弃。

为每个需要使用死信的业务队列配置一个死信交换机，同一个项目的死信交换机可以共用一个，然后为每个业务队列分配一个单独的routeKey，死信队列只不过是绑定在死信交换机上的队列，死信交换机也不是什么特殊的交换机，只不过是用来接受死信的交换机，所以可以为任何类型【Direct，Fanout，Topic】

TTL：一条消息或者该队列中的所有消息的最大存活时间

如果一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没有被消费，则会成为“死信”。如果同时设置了队列的TTL和消息的TTL，那么较小的那个值将会被使用。

只需要消费者一直消费死信队列里的消息。

```java
arguments.put("x-dead-letter-exchange", "dlx.exchange");
channel.queueDeclare(queueNamem, true, false, false, atguments);
channel.queueBind(queueName, exchangeName, routingKey);
channel.exchangeDeclare("dlx.exchange", "topic", true, false, null);
channel.queueDeclare("dlx.queue", true, false, false, null);
channel.queueBind("dlx.queue", "dlx.exchange", "#");
```

### 18. RabbitMQ如何保证消息的可靠性传输

1.  使用事务消息

2.  使用消息确认机制

    发送方确认：

    -   channel设置为confirm模式，则每条消息会被分配一个唯一id
    -   消息投递成功，信道会发送ack给生产者，包含了id，回调ConfirmCallback接口
    -   如果发生错误导致消息丢失，发生nack给生产者，回调ReturnCallback接口
    -   ack和nack只有一个触发，且只有一次，异步触发，可以继续发送消息

    接收方确认：

    -   声明队列时，指定nack=false，broker会等待消费者手动返回ack，才会删除消息，否则立刻删除
    -   broker的ack没有超时机制，只会判断链接是否断开，如果断开，消息会被重新发送。

### 19. RabbitMQ事务消息

通过对信道的设置实现：

1.  channel.txSelect()：通知服务器开启事务模式；服务端会返回Tx.Select-Ok；
2.  channel.basicPublish：发送消息，可以是多条，可以是消费消息提交ack；
3.  channel.txCommit()提交事务；
4.  channel.txRollback()回滚事务。

消费者使用事务：

1.  autoAck=false，手动提交ack，以事务提交或回滚为准；
2.  autoAck=true，不支持事务的，也就是说你即使在收到消息之后再回滚事务也是于事无补的，队列已经把消息移除了。

如果其中任意一个环节出现问题，就会抛出IOException异常，用户可以拦截异常进行事务回滚，或决定要不要重复消息。

事务消息会降低RabbitMQ的性能。

### 20. RabbitMQ如何确保消息发送？消息接收？

发送方确认机制：

```
信道需要设置为confirm模式，则所有在信道上发布的消息都会分配一个唯一ID。
一旦消息被投递到queue（可持久化的消息需要写入磁盘），信道会发送一个确认给生产者（包含消息唯一ID）。
如果RabbitMQ发生内部错误从而导致消息丢失，会发送一条nack（未确认）消息给生产者。
所有被发送的消息都将被confirm（即ack）或者被nack一次。但是没有对消息被confirm的快慢做任何保证，并且同一条消息不会既被confirm又被nack。
发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息，当确认消息到达生产者，生产者的回调方法会被触发。
ConfirmCallback接口：只确认是否正确到达Exchange中，成功到达则回调
ReturnCallback接口：消息失败返回时回调。
```

接收方确认机制：

```
消费者子啊声明队列时，可以指定nack参数，当nack=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存（或者磁盘，持久化消息）中移除消息。否则，消息被消费后会被立即删除。

消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ才能安全地把消息从队列中删除。

RabbitMQ不会为未ack的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开，这么设计的原因是RabbitMQ允许消费者消费一条消息的时间可以很长，保证数据的最终一致性。

如果消费者返回ack之前断开了连接，RabbitMQ会重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）。
```

### 21. RabbitMQ可以直连队列吗

生产者和消费者使用相同的参数声明队列，重复声明不会改变队列

```java
// 生产者
channel.queueDeclare(QUEUE_NAME, false, false, false, null);

// 消费者
channel.quyeueDeclare(QUEUE_NAME, false, false, false, null);
```

```
channel.queueDeclare(queue, durable, exclusive, autoDelete, arguments);
queue: 队列名字
durable: 队列持久化标志，true为持久化队列
exclusive: 排他队列，仅对创建的链接可见，链接中的channel都可见，其他链接不能重复声明，链接关闭队列会被自动删除。
autoDelete: 自动删除，如果该队列没有任何订阅的消费者的话，该队列会被自动删除，这种队列适用于临时队列
arguments: Map类型，队列参数设置
	x-message-ttl: 数字，消息队列中消息的存活时间，超过会被删除
	x-expires: 数字，队列自身的空闲时间，指定时间内没有被访问，就会被删除
	x-max-length和x-max-length-bytes: 队列最大长度和时间，超出会删除老的数据
	x-dead-letter-exchange和x-dead-letter-routing-key: 设置死信
	x-max-priotity: 队列支持的优先级别，需要生产者在发送消息时指定，消息按照优先级从到到低分发给消费者
```

```java
channel.basicPublish(exchange, routingkey, mandatory, immediate, basicProperties, body);
exchange: 交换机名
routingkey: 路由健
mandatory: 为true时，如果exchange根据自身类型和消息routingkey无法找到一个符合条件的queue，那么会调用basic.return方法将消息返回给生产者，channel.addReturnListener添加一个监听器，当broker执行basic.return方法时，会回调handleReturn方法，这样就可以处理变为死信的消息了；设为false时，出现上述清醒broker会直接将消息扔掉；
immediate: 3.0以前这个标志会告诉服务器如果该消息关联的queue上有消费者，则马上将消息投递给它，如果所有queue都没有消费者，直接把消息返还给生产者，不用将消息入队列等待消费者了。3.0之后取消了该参数
basicProperties: 消息的详细属性，优先级别，持久化，到期时间，headers类型的exchange要用到的是其中的headers字段
body: 消息实体，字节数组。
```

```
QueueingConsumer: 一个已经实现好了的Consumer，相比于自己实现Consumer接口，这是个比较安全快捷的方式，该类基于jdk的BlockingQueue实现，handleDelivery方法中将受到的消息封装成Delivery对象，并存放到BlockingQueue中，这相当于消费者本地存放了一个消息缓存队列，nextDelivery()方法底层调用的BlockingQueue的阻塞方法take()。

channel.basicConsume(queue, autoAck, consumer);
queue: 队列名
autoAck: 自动应答标识，true为自动应答
consumer: 消费者对象，可以自己实现Consumer接口，建议使用QueueingConsumer。
```

### 23. RocketMQ如何保证不丢消息

生产者：

-   同步阻塞的方式发送消息，加上失败重试机制，可能broker存储失败，可以通过查询确认
-   异步发送需要重写回调方法，检查发送结果
-   ack机制，可能存储CommitLog，存储ConsumerQueue失败，此时对消费者不可见

broker：同步刷盘，集群模式下采用同步复制，会等待slava复制完成才会返回确认

消费者：

-   offset手动提交，消息消费保证幂等

### 24. RabbitMQ死信队列，延时队列

1.  消息被消费方否定确认，使用channel.basicNack或channel.basicReject，并且此时requeue属性被设置为false
2.  消息在队列的存活时间超过设置的TTL时间
3.  消息队列的消息数量已经超过最大队列长度

那么该消息将成为"死信"，"死信"消息会被RabbitMQ进行特殊处理，如果配置了死信队列信息，那么该消息将会被丢进死信队列中，如果没有配置，则该消息将会被丢弃

为每个需要使用死信的业务队列配置一个死信交换机，同一个项目的死信交换机可以公用一个，然后为每个业务队列分配一个单独的路由key，死信队列只不过是绑定在死信交换机上的队列，死信交换机也不是什么特殊的交换机，只不过是用来接受死信的交换机，所有可以为任何类型【Direct，Fanout，Topic】

TTL：一条消息或者该队列中的所有消息的最大存活时间

如果一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没有被消费，则会成为"死信"，如果同时配置了队列的TTL和消息的TTL，那么娇小的那个值将会被使用

只需要消费者一直消费死信队列里的消息。

### 25. RocketMQ的底层实现原理

RocketMQ由NameServer集群，Producer集群，Consumer集群，Broker集群组成，消息生产和消费的大致原理如下：

1.  Broker在启动的时候向所有的NameServer注册，并保持长连接，每30s发送一次心跳
2.  Producer在发送消息的时候从NameServer获取Broker服务器地址，根据负载均衡算法选择一台服务器来发送消息
3.  Consumer消费消息的时候同样从NameServer获取Broker地址，然后主动拉取消息来消费

### 26. RocketMQ事务消息原理

依赖于TransactionListener接口

-   executeLocalTransaction方法会在发送消息后调用，用于执行本地事务，如果本地事务执行成功，rocketMQ再提交消息。
-   checkLocalTransaction用于对本地事务做检查，rocketMQ依赖此方法做补偿

prepare：将消息（消息上带有事务标识）投递到一个名为RMS_SYS_TRANS_HALF_TOPIC的topic中，而不是投递到真正的topic中

commit/rollback：producer再通过TransactionListener的executeLocalTransaction方法执行 本地事务，当producer的LocalTransaction处理成功或者处理失败后，produer会向broker发送commit或rollback命令，如果是commit，则broker会将投递到RMQ_SYS_TRANS_HALF_TOPIC中的消息投递到真实的topic中，然后再投递一个表示删除的消息到RMQ_SYS_TRANS_HALF_TOPIC中，表示当前事务已完成；如果是rollback，则没有投递到真实topic的过程，只需要投递表示删除的消息到RMQ_SYS_TRANS_OP_HALF_TOPIC。最后，消费者和消费普通的消息一样消费事务消息。

-   第一阶段（prepare）失败：给应用返回发送消息失败
-   事务失败：发送回滚命令给broker，由broker执行消息的回滚
-   Commit或rollback失败：由broker定时向producer发起事务检查，如果本地事务成功，则提交消息事务，否则回滚消息事务

事务状态的检查有两种情况：

-   commit/rollback：broker会执行响应的的commit/rollback操作
-   如果是TRANSACTION_NOT_TYPE，则一段时间后会再次检查，当检查的次数超过上限（默认15次）则丢弃消息。

### 27. Kafka的Rebalance机制

consumer group中的消费者与topic下的partion重新匹配的过程

何时会产生rabalance：

-   consumer group中的成员个数发生变化
-   consumer消费超时
-   group订阅的topic个数发生变化
-   group订阅的topic的分区数发生变化

coordinator：通常是partition的leader节点所在的broker，负责监控group中consumer的存活，consumer维持到coordinator的心跳，判断consumer的消费超时

-   coordinator通过心跳返回通知consumer进行rebalance
-   consumer请求coordinator加入组，coordinator选举产生leader consumer
-   leader consumer从coordinator获取所有的consumer，发送syncGroup（分配信息）给到coordinator
-   coordinator通过心跳机制将syncGroup下发给consumer
-   完成rebalance

leader consumer监控topic的变化，通知coordinator触发rebalance

如果c1消费消息超时，触发rebalance，重新分配后，该消息会被其他消费者消费，此时c1消费完成提交offset，导致错误。

解决：coordinator每次rebalance，会标记一个Generation给到consumer，每次rebalance改Generation会+1，consumer提交offset时，coordinator会比对Generation，不一致则拒绝提交。

### 28. Kafka的副本同步机制



![Kafka](%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.assets/Kafka.png)

-   LEO：下一条待写入位置

-   HW：High Water 高水位（ISR机制：所有已同步分区列表）

-   firstUnstableOffset：第一条未提交数据

-   LastStableOffset：最后一条已提交数据

-   LogStartOffset：起始位置

-   isolation.level=read_commited：只能消费到LastStableOffset，read_commited可以消费到HW的上一条

-   一个partition对应的ISR中最小的LEO作为分区的HW，consumer最多只能消费到HW所在的位置

-   Leader收到消息后更新本地的LEO，leader还会维护follower的LEO即remote LEO，follower发出fetch同步数据请求时（携带自身的LEO），leader会更新remote LEO，更新分区的HW，然后将数据响应给follower，follower更新自身HW（取响应中的HW和自身的LEO中的较小值），LEO+1

-   ISR：如果一个follower落后leader不超过某个时间阈值，那么在ISR中，否则将放在OSR中

    同步副本时，follower获取leader的LEO和LogStartOffset，与本地对比，如果本地的LogStartOffset超出了leader的值，则超过这个值的数据删除，再进行同步，如果本地的小于leader的，则直接同步。

    

    *HW下面的数据可以被消费者消费，HW上面的数据消费者不可见。*

### 29. RocketMQ怎么实现顺序消息

默认是不能保证的，需要程序保证发送和消费的是同一个queue，多线程消费也无法保证。

发送顺序：发送端自己业务逻辑保证先后，发往一个固定的queue，生产者可以在消息体上设置消息的顺序

发送者实现MessageQueueSelector接口，选择一个queue进行发送，也可使用RocketMQ提供的默认实现

-   SelectMessageQueueByHash：按参数的hashcode与可选队列进行求余选择
-   SelectMessageQueueByRandom：随机选择

mq：queue本身就是顺序追加写，只需保证一个队列统一时间只有一个consumer消费，通过加锁实现，consumer上的顺序消费有一个定时任务，每隔一定时间向broker发送请求延长锁定。

消费端：

-   pull模式：消费者需要自己维护需要拉取的queue，一次拉取的消息都是无顺序的，需要消费端自己保证顺序消费
-   push模式：消费实例实现自MQPushConsumer接口，提供注册监听的方法消费消息
-   registerMessageListener，重载方法
    -   MessageListenerConcurrently：并行消费
    -   MessageListenerOrderly：串行消费，consumer会把消息放入本地队列并加锁，定时任务保证锁的同步

### 30. Kafka架构设计

![Kafka架构设计](%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.assets/Kafka%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1-1636959258237.png)

-   Consumer Group：消费者组，消费者组内每个消费者负责消费不同分区的数据，提高消费能力，逻辑上的一个订阅者
-   Topic：可以理解为一个队列，Topic将消息分类，生产者和消费者面向的是同一个Topic
-   Partition：为了实现扩展性，提高并发能力，一个Topic以多个Partition的方式分布到多个Broker上，，每个Partition是一个有序的队列，一个Topic的每个Partition都有若干个副本（Replica），一个Leader和若干个Follower，生产者发送数据的对象，以及消费者消费数据的对象，都是Leader，Follower负责实时从Leader中同步数据，保持和Leader数据的同步，Leader发生故障时，某个Follower还会成为新的Leader。

### 31. RabbitMQ的持久化机制

1.  交换机持久化：exchange_declare创建交换机时通过参数指定
2.  队列持久化：queue_declare创建队列时通过参数指定
3.  消息持久化：new AMQPMessage创建消息时通过参数指定

append的方式写文件，会根据大小自动生成新的文件，rabbitMQ启动时会创建两个进程，一个负责持久化消息的存储，另一个负责非持久化消息的存储（内存不够时）

消息存储时会在ets表中记录消息在文件中的映射以及相关信息（包括id，偏移量，有效数据，左边文件，右边文件），消息读取时根据该信息到文件中读取，同时更新信息。

消息删除时只从ets删除，变为垃圾数据，当垃圾数据超出比例（默认50%），并且文件数达到3个，触发垃圾回收，锁定左右两个文件，整理左边文件有效数据，将右边文件有效数据写入左边，更新文件信息，删除右边，完成合并。当一个文件的有用数据等于0时，删除该文件

写入文件前先写buffer缓冲区，如果buffer已满，则写入文件（此时只是操作系统的页存）

每隔25ms刷一次磁盘，不管buffer满没满，都将buffer和页存中的数据落盘

每次消息写入后，如果没有后续请求，则直接刷盘

### 32. RabbitMQ的交换机类型

交换机分发会先找出绑定的队列，然后再判断`routekey`，来决定是否将消息分发到某一个队列中

```java
Channel channel = connection.createChannel(); // 在rabbitMQ中创建一个信道
channel.exchangeDeclare("exchangeName", "direct"); // 创建一个type为direct的交换机
channel.queueDeclare("queueName"); // 创建一个队列
channel.queueBind("queueName", "exchangeName", "zhangsan"); // 绑定并设置路由键
channel.queueBind("queueName", "exchangeName", "lisi"); // 绑定并设置路由键
channel.queueBind("queueName", "exchangeName", "wangwu"); // 绑定并设置路由键
```

fanout：扇形交换机，不再判断routekey，直接将消息分发到所有绑定的队列

direct：判断routekey的规则是完全匹配模式，即发送消息时指定的routekey要等于绑定的routekey

topic：判断routekey的规则是模糊匹配模式

header：绑定队列与交换机的时候指定一个键值对，当交换机在分发消息的时候会先接口消息体里的headers数据，然后判断里面是否有所设置的键值对，如果发现匹配成功，才将消息分发到队列中；这种交换机类型在性能上相对来说较差，在实际工作中很少会用到。

### 33. RabbitMQ的普通集群模式

![RabbitMQ的普通集群](%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.assets/RabbitMQ%E7%9A%84%E6%99%AE%E9%80%9A%E9%9B%86%E7%BE%A4.png)

元数据：

-   队列元数据：队列名称和它的属性
-   交换机元数据：交换机名称，类型和属性
-   绑定元数据：一张简单的表格展示了如何将消息路由到队列
-   vhost元数据：为vhost内的队列，交换机和绑定提供命名空间和安全属性

为什么只同步元数据：

-   存储空间，每一个节点都保存全量数据，影响消息堆积能力
-   性能，消息的发布需要将消息复制到每一个集群节点

客户端连接的是非队列数据所在节点：则该节点会进行路由转发，包括发送和消费

集群节点类型：

-   磁盘节点：将配置信息和元信息存储在磁盘上
-   内存节点：将配置信息和元信息存储在内存中，性能优于磁盘节点，依赖磁盘节点进行持久化

RabbitMQ要求集群中至少有一个磁盘节点，当节点加入和离开集群时，必须通知磁盘节点（如果集群中唯一的磁盘节点崩溃了，则不能进行创建队列，创建交换器，创建绑定，添加用户，更改权限，添加和删除集群节点）。如果唯一磁盘的磁盘节点崩溃，集群是可以保持运行的，但不能更改任何东西，因此建议在集群中设置两个磁盘节点，只要一个可以，就能正常操作。

### 34. RabbitMQ的架构设计

![RabbitMQ架构图](%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.assets/RabbitMQ%E6%9E%B6%E6%9E%84%E5%9B%BE.png)

**Broker**：RabbitMQ的服务节点

**Queue**：队列，是RabbitMQ的内部对象，用于存储对象。RabbitMQ中消息只能存储在队列中，生产者投递消息到队列，消费者从队列中获取消息并消费，多个消费者可以订阅同一个队列，这时队列中的消息会被平均分摊（轮询）给多个消费者进行消费，而不是每个消费者都受到所有的消息进行消费。（注意：RabbitMQ不支持队列层面的广播消费，如果需要广播消费，可以采用一个交换器通过路由key绑定多个队列，由多个消费者来订阅这些队列的方式。）

**Exchange**：交换机，生产者将消息发送到Exchange，由交换机将消息路由到一个或多个队列中，如果路由不到，或返回给生产者，或直接丢弃，或做其他处理。

**RoutingKey**：路由Key，生产者将消息发送给交换机的时候，一般会指定一个RoutingKey，用来指定这个消息的路由规则，这个路由key需要与交换机类型和绑定键（BindingKey）联合使用才能最终生效，在交换机类型和绑定键固定的情况下，生产者可以在发送消息给交换机时通过指定RoutingKey来决定消息流向哪里。

**Binding**：通过绑定交换机和队列关联起来，在绑定的时候一般会指定一个绑定键，这样RabbitMQ就可以指定如何正确的路由到队列了。

交换机和队列实际上是多对多关系，就像关系数据库中的两张表，他们通过BindingKey做关联（多对多关系表）。在投递消息时，可以通过Exchange和RoutingKey（对应BindingKey）就可以找到相对应的队列。

**信道**：信道是建立在Connection之上的虚拟连接，当应用程序与Rabbit Broker建立TCP连接的时候，客户端紧接着可以创建一个AMQP信道（Channel），每个信道都会被指派一个唯一的ID，RabbitMQ处理的每条AMQP指令都是通过信道完成的。信道就像电缆里的光纤束，一条电缆内含有许多光纤束，允许所有的连接通过多条光纤束进行传输和接收。

### 35. RabbitMQ事务消息机制

通过对信道设置实现

1.  channel.txSelect()：通知服务器开启事务模式；服务端会返回tx.Select-Ok
2.  channel.basicPublish：发送消息，可以是多条，可以是消费消息提交ack
3.  channel.txCommit()：提交事务
4.  channel.txRollback()：回滚事务

消费者使用事务：

1.  autoAck=false，手动提交ack，以事务提交或回滚为准
2.  autoAck=true，不支持事务的，也就是说即使在收到消息之后在回滚事务也是于事无补的，队列已经把消息移除了

如果其中任意一个环节出现问题，就会抛出IOException异常，用户可以拦截异常进行事务回滚，或决定要不要重复消费，事务消息会降低RabbitMQ的性能。

### 36. 消息队列如何保证消息可靠传输

消息可靠传输代表了两层意思，既不能多也不能少

1.  为了保证消息不多，也就是消息不能重复，也就是生产者不能重复生产消息，或者消费者不能重复消费消息
    1.  首先要确保消息不多发，这个不常出现，也比较难控制，因为如果出现了多发，很大的原因是生产者自己的原因，如果要避免出现问题，就需要在消费端做控制
    2.  要避免不重复消费，最保险的机制就是消费者实现幂等性，保证就算重复消费，也不会有问题，通过幂等性，也能解决生产者重复发送消息的问题。
2.  消息不能少，意思就是消息不能丢失，生产者发送的消息，消费者一定要能消费到，对于这个问题，就要考虑两个方面
    1.  生产者发送消息时，要确认broker确实收到并持久化了这条消息，比如RabbitMQ的Confirm机制，Kafka的ack机制都可以保证生产者能正确的将消息发送给broker
    2.  broker要等待消费者真正确认消费到了消息时才删除掉消息，这里通常就是消费端ack机制，消费者接收到一条消息后，如果确认没问题了，就可以给broker发送一个ack，broker接收到ack之后才会删除消息。

### 37. RocketMQ的架构设计

![RocketMQ架构设计](%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.assets/RocketMQ%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1-1637062335570.png)

路由信息是包括了：BrokerServer，Topic和ConsumeQueue等信息。

### 38. RocketMQ持久化机制

-   commitLog：日志数据文件，被所有的queue共享，大小为1G，写满之后重新生成，顺序写
-   consumeQueue：逻辑queue，消息先到达commitLog，然后异步转发到consumeQueue，包含queue在CommitLog中的物理位置偏移量Offset，消息实体内容的大小和Message Tag的hash值。大小约为600w个字节，写满之后重新生成，顺序写。
-   indexFile：通过key或者时间区间来查找CommitLog中的消息，文件名以创建的时间戳命名，固定的单个IndexFile大小为400M，可以保存2000w个索引。

所有队列公用一个日志数据文件，避免了Kafka的分区数过多，日志文件过多导致磁盘IO读写压力较大造成性能瓶颈，RocketMQ的queue只存储少量数据，更加轻量化，对于磁盘的访问是串行化避免磁盘竞争，缺点在于：写入是顺序写，但读是随机的，先读ConsumeQueue，再读CommitLog，会降低消息读的效率。

消息发送到broker后，会被写入commitLog，写之前加锁，保证顺序写入，然后转发到consumeQueue。

消息消费时先从consumeQueue读取消息在commitLog中的起始物理偏移量Offset，消息大小，和消息Tag的HashCode值，再从commitLog读取消息内容。

-   同步刷盘：消息持久化到磁盘才会给生产者返回ack，可以保证消息可靠，但是会影响性能
-   异步刷盘：消息写入pageCache就返回ack给生产者，刷盘采用异步线程，降低读写延迟提高性能和吞吐。

### 39. 死信队列是什么？延时队列是什么？

1.  死信队列也是一个消息队列，它是用来存放那些没有成功消费的消息的，通常可以用来作为消息重试。
2.  延时队列就是用来存放需要在指定时间被处理的元素的队列，通常可以用来处理一些具有过期性操作的业务，比如十分钟内未支付则取消订单。

### 40. Kafka为什么比RocketMQ的吞吐量高

Kafka的生产者采用的是异步发送消息机制，当发送一条消息时，消息并没有发送到Broker而是缓存起来，然后直接向业务返回成功，当缓存的消息达到一定数量时再批量发送给Broker，这种做法减少了网络IO，从而提高了消息发送的吞吐量，但是如果消息生产者宕机，会导致消息丢失，业务出错，所以理论上Kafka利用此机制提高了性能却降低了可靠性。

### 41. 如何保证消息不被重复消费？

幂等：一个数据或者一个请求，重复来多次，确保对应的数据是不会改变的，不能出错

思路：

-   如果是写Redis，就没问题，反正每次都是set，天然幂等性
-   生产者发送消息的时候带上一个全局唯一的id，消费者拿到消息后，先根据这个id去redis里查一下，之前有没消费过，没有消费过就处理，并且写入这个id到redis，如果消费过了，则不处理
-   基于数据库的唯一键

### 42. 消息队列有哪些作用

1.  解耦：使用消息队列来作为两个系统之间的通讯方式，两个系统不需要相互依赖了
2.  异步：系统A给消息队列发送完消息之后，就可以继续做其他事情了
3.  流量削峰：如果使用消息队列的方式来调用某个系统，那么消息将在队列中排队，由消费者自己控制消费速度

### 43. 消息队列如何保证消息可靠传输

消息可靠传输代表了两层意思，既不能多也不能少

1.  为了保证消息不多，也就是消息不能重复，也就是生产者不能重复生产消息，或者消费者不能重复消费消息
2.  首先要确保消息不多发，这个不常出现，也比较难控制，因为如果出现了多发，很大的原因是生产者自己的原因，如果要避免出现问题，就需要在消费端做控制
3.  要避免不重复消费，最保险的机制就是消费者实现幂等性，保证就算重复消费，也不会有问题，通过幂等性，也能解决生产者重复发送消息的问题
4.  消息不能少，意思就是消息不能丢失，生产者发送的消息，消费者一定要能消费到，对于这个问题，就要考虑两个问题
5.  生产者发送消息时，要确认broker确实收到并持久化了这条消息，比如RabbitMQ的confirm机制，Kafka的ack机制都可以保证生产者能正确的将消息发送给broker
6.  broker要等待消费者真正确认消费到了消息时才删除掉消息，这里通常就是消费端ack机制，消费者接收到一条消息后，如果确认没问题了，就可以给broker发送一个ack，broker接收到ack之后才会删除消息

### 44. 如何设计一个MQ

MQ作用，项目大概的样子

1.  实现一个单机的队列数据结构。高效，可扩展。
2.  将单机队列扩展成为分布式队列。分布式集群管理
3.  基于topic定制消息路由策略。发送者路由策略，消费者与队列对应关系，消费者路由策略
4.  实现高效的网络通信。Netty Http
5.  规划日志文件，实现文件高效读写。零拷贝，顺序写。服务重启后快速还原运行现场。
6.  定制高级功能，死信队列，延时队列，事务消息等。

### 45. 消息队列的优缺点，使用场景

优点：

1.  解耦：降低系统之间的依赖
2.  异步：不需要同步等待
3.  削峰填谷：将流量从高峰期引到低谷期进行处理

缺点：

1.  增加了系统的复杂度，幂等，重复消费，消息丢失等问题的带入
2.  系统可用性降低，mq的故障会影响系统可用
3.  一致性，消费端可能失败

场景：日志采集，发布订阅等











































