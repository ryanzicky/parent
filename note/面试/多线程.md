### 1. 如何预防死锁

1.   死锁发生的四个必要条件：
     1.   互斥条件，同一时间只能有一个线程获取资源
     2.   不可剥夺条件，一个线程已经占有的资源，在释放之前不会被其他线程抢占
     3.   请求和保持条件，线程等待过程中不会释放已占有的资源
     4.   循环等待条件，多个线程互相等待对方释放资源
2.   死锁预防，那么就需要破坏者四个必要条件
     1.   由于资源互斥是资源使用的固有特性，无法改变
     2.   破坏不可剥夺条件
          1.   一个进程不能获得所需要的全部资源时便处于等待状态，等待期间他占有的资源将被隐式的释放重新加入到系统的资源列表中，可以被其他的进程使用，而等待的进行只有重新获得自己原有的资源以及新申请的资源才可以重新启动，执行
     3.   破坏请求与保持条件
          1.   第一种方法静态分配即每个进程在开始执行时就申请他所需要的全部资源
          2.   第二种是动态分配每个进程在申请所需要的资源时他本身不占用系统资源
     4.   破坏循环等待条件
          1.   采用资源有序分配其基本思想是将系统中的所有资源顺序编号，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号的顺序进行，一个进程只有获得较小编号的进程才能申请较大编号的进程

### 2. 多线程创建方式

1.   实现Runnable，Runnable规定的方法是run()，无返回值，无法抛出异常
2.   实现Callable，Callable规定的方法是call()，任务执行后有返回值，可以抛出异常
3.   继承Thread类创建多线程：继承java.lang.Thread类，重写Thread类的run()方法。在run()方法中实现运行在线程上的代码，调用start()方法开启线程。Thread类本质上是实现了Runnable接口的一个实例，代表一个线程的实例。启动线程的唯一方法就是通过Thread类的start()实例方法，start()方法是一个native方法，它将启动一个新线程，并执行run()方法。
4.   通过线程池创建线程，线程和数据库连接这些资源都是非常宝贵的资源，那么每次需要的时候创建，不需要的时候销毁，是非常浪费资源的，那么我们就可以采用缓存的策略，也就是使用线程池。

### 3. 线程安全活跃态问题，竞态条件

1.   线程安全的活跃性问题可以分为死锁，活锁，饥饿
     1.   活锁：就是有时线程虽然没有发生阻塞，但是仍然会存在执行不下去的情况，活锁不会阻塞线程，线程会一直重复执行某个相同的操作，并且一直失败重试
          1.   我们开发中使用的异步消息队列就有可能造成活锁的问题，在消息队列的消费端如果没有正确的ack消息，并且执行过程中报错了，就会再次放回消息头，然后再拿出来执行，一直循往复的失败。这个问题除了正确的ack之外，往往是通过将失败的消息放入到延时队列中，等到一定的延时再进行重试来解决。
          2.   解决活锁的方案很简单，尝试等待一个随机的时间就可以，会按时间轮去重试。
     2.   饥饿：就是线程因无法访问所需资源而无法执行下去的情况
          1.   饥饿分为两种情况：
               1.   一种是其他的线程在临界区做了无限循环或无限制等待资源的操作，让其他的线程一直不能拿到锁进入临界区，对其他线程来说，就进入了饥饿状态
               2.   另一种是因为线程优先级不合理的分配，导致部分线程始终无法获取到cpu资源而一直无法执行
          2.   解决饥饿的问题有几种方案：
               1.   保证资源充足，很多场景下，资源的稀缺性无法解决
               2.   公平分配资源，在并发编程里使用公平锁，例如FIFO策略，线程等待是有顺序的，排在等待队列前面的线程会优先获得资源
               3.   避免持有锁的线程长时间执行，很多场景下，持有锁的线程的执行时间也很难缩短
     3.   死锁：线程在对同一把锁进行竞争的时候，未抢占到锁的线程会等待持有锁的线程释放锁后继续抢占，如果两个或两个以上的线程互相持有对方将要抢占的锁，互相等待对方优先释放锁就会进入到一个循环等待的过程，这个过程就叫做死锁。
     4.   线程安全的竞态条件问题：
          1.   同一个程序多线程访问同一个资源，如果对资源的访问顺序敏感，就称存在竞态条件，代码去成为临界区，大多数并发错误一样，竞态条件不总是会产生问题，还需要不恰当的执行时序
          2.   最常见的竞态条件为：
               1.   先检测后执行执行依赖于检测的结果，而检测结果依赖于多个线程的执行时序，而多个线程的执行时序通常情况下是不固定不可判断的，从而导致执行结果出现各种问题，这一种可能的解决办法就是：在一个线程修改访问一个状态时，要防止其他线程访问修改，也就是加锁机制，保证原子性。
               2.   延迟初始化（典型为单例）

### 4. Java中的wait和sleep的区别和联系

1.   所属类：首先，这两个方法来自不同的类分别是Thread和Object，wait是Object的方法，sleep是Thread的方法
     1.   sleep方法属于Thread类中的方法，表示让一个线程进入睡眠状态，等待一定时间之后，自动醒来进入到可运行状态，不会马上进入运行状态，因为线程调度机制恢复线程的运行也需要时间，一个线程对象调用了sleep方法之后，并不会释放它所持有的所有对象锁，所以也就不会影响其他进程对象的方法。但在sleep的过程中有可能被其他对象调用它的interrupt()方法，产生InterruptedException异常，如果你的程序不捕获这个异常，线程就会异常终止，进入TERMINATED状态，如果你的程序捕获了这个异常，那么程序就会继续执行catch语句块（可能还有finally语句块）以及以后的代码
2.   作用范围：sleep方法没有释放锁，只是休眠，而wait释放了锁，使得其他线程可以使用同步控制块或方法
3.   使用范围：wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用
4.   异常范围：sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常

### 5. 进程与线程的区别

1.   进程（process）
     1.   是系统进行资源分配和调度的基本单位，是操作系统结果的基础。在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令，数据及其组织形式的描述，进程是程序的实体，是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。程序是指令，数据及其组织形式的描述，进程是程序的实体。总结：进程是指在系统中正在运行的一个应用程序；程序一旦运行就是进程；进程--资源分配的最小单位。
2.   线程
     1.   操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。总结：系统分配处理器时间资源的基本单元，或者说进程之内独立执行的一个单元执行流，线程--程序执行的最小单位。

### 6. Java线程的生命周期

大致5个阶段：

-   新建：就是刚使用new方法，new出来的线程
-   就绪：就是调用的线程的start()方法，这时候线程处于等待CPU分配资源阶段，谁先抢到CPU的资源，谁开始执行
-   运行：当就绪的线程被调度并获得CPU资源时，便进入运行状态，run方法定义了线程的操作和功能；
-   阻塞：在运行状态的时候，可能因为某些原因导致运行状态的线程变成了阻塞状态，比如sleep()，wait()之后线程就处于阻塞状态，这个时候需要其他机制将处于阻塞状态的线程唤醒，比如调用notify()和或者notifyAll()方法，唤醒的线程不会立刻执行run()方法，它们要再次等待CPU分配资源进入运行状态。
-   销毁：如果线程正常执行完毕后或线程被提前强制性的终止或出现异常导致结束，那么线程就要被销毁，释放资源

从JDK源码分析，Thread的状态：

	1. NEW：尚未启动的线程的线程状态
	1. RUNNABLE：处于可运行状态的线程正在Java虚拟机中运行，但它可能正在等待来自操作系统（例如处理器）的其他资源
	1. BLOCKED：线程的线程状态被阻塞，等待监视器锁定，Synchroized拿不到线程锁
	1. WAITING：处于等待状态的线程正在等待另一个线程执行特定操作：例如：在对象上调用了Object.wait()的线程正在等待另一个线程调用Object.notify()或者Object.notifyAll()，调用了Thread.join()的线程正在等待指定的线程终止
	5. TIMED_WATING：具有指定等待时间的等待线程的线程状态，由于以指定的正在等待时间调用以下方法之一，因此线程处于定时等待状态：
	 	1. Thread.sleep(long)
	 	2. Object#wait(long)
	 	3. Thread.join(long)
	 	4. LockSupport.parkNanos(long...)
	 	5. LockSupport.parkUnit(long...)

### 7. 程序开多少线程合适

这里需要区别下应用是什么样的程序：

1.   CPU密集型程序，一个完整的请求，I/O操作可以在很短时间内完成，CPU还有很多运算要处理，也就是说CPU计算的比例占很大一部分，线程等待时间接近0

     1.   单核：一个完整的请求，I/O操作可以在很短时间内完成，CPU还有很多运算要处理，也就是说CPU计算的比例占很大一部分，线程等待时间接近0。单核CPU处理CPU密集型程序，这种情况并不太适合使用多线程。

     2.   多核：如果是多核CPU处理CPU密集型程序，我们完全可以最大化的利用CPU核心数，应用并发编程来提高效率。CPU密集型程序的最佳线程数就是：因此对于CPU密集型来说，理论上线程数量=CPU核数（逻辑），但是实际上，数量一般会设置为CPU核数（逻辑）+ 1（经验值）

          计算（CPU）密集型的线程恰好在某时因为发生一个页错误或者因其他原因而暂停，刚好有一个“额外” 的线程，可以确保在这种情况下CPU周期不会中断工作。

2.   I/O密集型程序：与CPU密集型程序相对，一个完整的请求，CPU运算操作完成之后还有很多I/O操作要做，也就是说I/O操作占比很大部分，等待时间较长，线程等待时间所在比例越高，需要越多线程；线程CPU时间所在比例越高，需要越少线程。

     1.   I/O密集型程序的最佳线程数就是：最佳线程数=CPU核心数（1/CPU利用率）=CPU核心数（1+（I/O耗时/CPU耗时））
     2.   如果几乎全是I/O耗时，那么CPU耗时就无限趋近于0，所以理论就可以说是2N（N=CPU核数），当然也有说2N+1的，1应该就是backup
     3.   一般我们说2N+1即可

### 8. notify和notifyAll区别

1.   锁池和等待池的概念
     1.   锁池：假设线程A已经拥有了某个对象（注意：不是类）的锁，而其他的线程想要调用这个对象的某个synchronized方法（或者synchronize块），由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。
     2.   等待池：假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁（因为wait()方法必须出现在synchronized中，这样自然在执行wait()方法之前线程A就已经拥有了该对象的锁），同时线程A就进入到了该对象的等待池中。如果另外的一个线程调用了相同对象的notifyAll()方法，那么处于该对象的等待池中的线程就会全部进入该对象的锁池中，准备争夺锁的拥有权。如果另外的一个线程调用了相同对象的notify()方法，那么仅仅有一个处于该对象的等待池中的线程（随机）会进入该对象的锁池。
2.   如果线程调用了对象的wait()方法，那么线程便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁
3.   当有线程调用了对象的notifyAll()方法（唤醒所有wait线程）或notify()方法（只随机唤醒一个wait线程），被唤醒的线程便会进入该对象的锁池中，所持中的线程会去竞争该对象锁，也就是说，调用了notify后只有一个线程会由等待池进入锁池，而notifyAll会将该对象等待池内的所有线程移动到锁池中，等待锁竞争
4.   所谓唤醒线程，另一种解释可以说是将线程由等待池移动到锁池，notifyAll调用后，会将全部线程由等待池移到锁池，然后参与锁的竞争，竞争成功则继续执行，如果不成功则留在锁池等待锁被释放后再次参与竞争，而notify只会唤醒一个线程。

### 9. synchronize和lock区别

| 区别类型     | synchronized                                                 | lock                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存在层次     | Java的关键字，在jvm层面上                                    | 是JVM的一个接口                                              |
| 锁的获取     | 假设A线程获的锁，B线程等待。如果A线程阻塞，B线程会一直等待   | 情况而定，Lock有多个锁获取的方式，大致就是可以尝试获得锁，线程可以不用一直等待（可以通过tryLock判断又没有锁） |
| 锁的释放     | 1. 已获取锁的线程执行完同步代码，释放锁；2. 线程执行发生异常，JVM会让线程释放 | 在finally中必须释放锁，不然容易造成线程死锁                  |
| 锁类型       | 锁可重入，不可中断，非公平                                   | 可重入，可判断，可公平（两者皆可）                           |
| 性能         | 少量同步                                                     | 适用于大量同步                                               |
| 支持锁的场景 | 1. 独占锁                                                    | 1. 公平sup与非公平锁                                         |

### 10. ABA问题

1.   有两个线程同时去修改一个变量的值，比如线程1，线程2，都更新变量值，将变量值从A更新成B

2.   首先线程1，获取到CPU的时间片，线程2由于某些原因发生阻塞进行等待，此时线程1进行比较更新（CompareAndSwap），成功将变量的值从A更新成B

3.   更新完毕之后，恰好又有线程3进来想要把变量的值从B变成A，线程3进行比较更新，成功将变量的值从B变成A

4.   线程2获取到CPU的时间片，然后进行比较更新，发现值是预期的A，然后又更新成了B，但是线程1并不知道，该值已经有了

     A -> B -> A这个过程，就是ABA问题

5.   可以通过加版本号或者加时间戳解决，或者保证单向递增或者递减就不会存在此类问题。

### 11. DCL

```java
public class Singleton {
	// volatile是防止指令重排
    private static volatile Singleton singleton;
    private Singleton() {}
    
    public static Singleton getInstance() {
        // 第一层判断singleton是不是为null
        // 如果不是null直接返回，这样就不必加锁了
        if (singleton == null) {
            // 现在再加锁
            synchronized (Singleton.class) {
                // 第二层判断
                // 如果A，B两个线程都在synchronized等待
                // A创建完对象之后，B还会再进入，如果不再检查一遍，B又会创建一个对象
                if (singleton == null) {
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
```

### 12. 实现一个阻塞队列（用Condition写生产者与消费者）

```java
public class ProviderConsumer<T> {
    private int length;
    private Queue<T> queue;
    private ReentrantLock lock = new ReentrantLock();
    private Condition providerCondition = lock.newCondition();
    private Condition consumerCondition = lock.newCondition();
    
    public ProviderConsuer(int length) {
        this.length = length;
        this.queue = new LinkedList<T>();
    }
    
    public void provider(T product) {
        lock.lock();
        try {
            while (queue.size >= length ) {
                providerCondition.await();
            }
            queue.add(product);
            consumerCondition.signal();
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finallt () {
            lock.unlock();
        }
    }
    
    public void consumer() {
        lock.lock();
        try {
            while (queue.isEmpty()) {
                consumerCondition.awati();
            }
            T product = queue.remove();
            providerCondition.signal();
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally () {
            lock.unlock();
        }
    }
}
```

### 13. 实现多个线程顺序打印ABC

```java
public class PrintABC {
	ReentrantLock lock = new EeentrantLock();
    Condition conditionA = lock.newCondition();
    Condition conditionB = lock.newCondition();
    Condition conditionC = lock.newCondition();
    
    volatile int value = 0;
    // 打印多少遍
    private int count;
    
    public PrintABC(int count) {
        this.count = count;
    }
    
    pubilc void printABC() {
        new Thread(new ThreadA()).start();
        new Thread(new ThreadB()).start();
        new Thread(new ThreadC()).start();
    }
    
    class ThreadA implements Runnable {
        @Override
        public vid run() {
            lock.lock();
            try {
                fot (int i = 0; i < count; i++) {
                   while (value % 3 != 0) {
                       conditionA.await();
                   } 
                    System.out.println("A");
                    conditionB.signal();
                    value++;
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally () {
                lock.unlock();
            }
        }
    }
    
    class ThreadB implements Runnable {
        @Override
        public vid run() {
            lock.lock();
            try {
                fot (int i = 0; i < count; i++) {
                   while (value % 3 != 1) {
                       conditionB.await();
                   } 
                    System.out.println("B");
                    conditionC.signal();
                    value++;
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally () {
                lock.unlock();
            }
        }
    }
    
    class ThreadC implements Runnable {
        @Override
        public vid run() {
            lock.lock();
            try {
                fot (int i = 0; i < count; i++) {
                   while (value % 3 != 2) {
                       conditionC.await();
                   } 
                    System.out.println("C");
                    conditionA.signal();
                    value++;
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally () {
                lock.unlock();
            }
        }
    }
}
```

### 14. 服务器CPU数量及线程池线程数量的关系

首先确认是CPU密集型还是IO密集型的

如果是CPU密集型的，那么就应该尽量少的线程数量，一般为CPU的核数+1

如果是IO密集型的：可多分配一点CPU核数*2也可以使用公式：CPU核数  / （1 - 阻塞系数）；其中阻塞系数在0.8~0.9之间。

### 15. 多线程之间是如何通信的

1.   通过共享变量，变量需要volatile修饰
2.   使用wait()和notify()方法，但是由于需要使用同一把锁，所以必须通知线程释放锁，被通知线程才能获取到锁，这样导致通知不及时。
3.   使用CountDownLatch实现，通知线程到指定条件，调用countDownLatch.countDown()，被通知线程进行countDownLatch.await()；
4.   使用Condition的await()和signalAll()方法
5.   Future，Pipeline（管道流）

### 16. synchronized底层实现，以及和lock的区别

### 17. synchronized关键字加在静态方法和实例方法的区别

修饰静态方法，是对类进行加锁，如果该类中有methodA和methodB都是被synchronized修饰的静态方法，此时有两个线程T1，T2分别调用methodA()和methodB()，则T2会阻塞等待直到T1执行完成之后才能执行。

修饰实例方法时，是对实例进行加锁，锁的是实例对象的对象头，如果调用同一个对象的两个不同的被synchronized修饰的实例方法时，看到的效果和上面的一样，如果调用不同对象的两个不同的被synchronized修饰的实例方法时，则不会阻塞。

### 18. CountDownLatch的用法

两种用法：

1.   让主线程await()，业务线程进行业务处理，处理完成时调用countDownLatch.countDown()，CountDownLatch实例化的时候需要根据业务去选择CountDownLatch的count；
2.   让业务线程await，主线程处理完数据之后进行countDownLatch.countDown()，此时业务线程被唤醒，然后去主线程拿数据，或者执行自己的业务逻辑。

### 19. 线程池问题：

1.   Executor提供了集中线程池：

     1.   `newCachedThreadPool()`（工作队列使用的是SynchronsQueue，线程池无限大）

          创建一个线程池，如果线程池中的线程数量过大，它可以有效的回收多余的线程，如果线程数不足，那么它可以创建新的线程。

          不足：这种方式虽然可以根据业务场景自动的扩展线程数来处理我们的业务，但是最多需要多少个线程同时处理却是我们无法控制的。

          优点：如果当第二个任务开始，第一个任务已经执行结束，那么第二个任务会复用第一个任务创建的线程，并不会重新创建新的线程，提高了线程的复用率。

          作用：该方法返回一个可以根据实际情况调整线程池中线程的数量的线程池。即该线程池中的线程数量不确定，是根据实际情况动态调整的。

     2.   `newFixedThreadPool()`（工作队列使用的是LinkedBlockingQueue）

          这种方式可以指定线程池中的线程数，如果满了后又来了新任务，此时只能排队等待

          优点：newFixedThreadPool的线程数是可以进行控制的，因此我们可以通过控制最大线程来使我们的服务器达到最大的使用率，同时又可以保证即使流量突然增大也不会占用服务器过多的资源。

          作用：该方法返回一个固定线程数量的线程池，该线程池中的线程数量始终不变，即不会再创建新的线程，也不会销毁已经创建好的线程，自始至终都是那几个固定的线程在工作，所以该线程池可以控制线程的最大并发数

     3.   `newScheduledThreadPool()`

          该线程池支持定时，以及周期性的任务执行，我们可以延迟任务的执行时间，也可以设置一个周期性的时间让任务重复执行。该线程池有一下两种延迟的方法：

          1.   `scheduleAtFixedRate`：不同的地方是任务的执行时间，如果间隔时间大于任务的执行时间，任务不受执行时间的影响。如果间隔时间小于任务的执行时间，那么任务执行结束之后，会立马执行，至此间隔时间就会被打乱。
          2.   `scheduleWithFixedDelay`：间隔时间不会收任务执行时间长短的影响

          作用：该方法返回一个可以控制线程池内线程定时或周期性执行某任务的线程池。

     4.   `newSingleThreadExecutor()`

          这是一个单线程池，自始至终都由一个线程来执行

          作用：该方法返回一个只有一个线程的线程池，即每次只能执行一个线程任务，多余的任务会保存到一个任务队列中，等待这一个线程空闲，当这个线程空闲了再按FIFO方式顺序执行任务队列中的任务。

     5.   `newSingleThreadScheduledExecutor()`

          只有一个线程，用来调度任务在指定时间执行

          作用：该方法返回一个可以控制线程池内线程定时或周期性执行某任务的线程池，只不过和上面的区别就是该线程池大小为1，而上面的可以指定线程池的大小

2.   线程池的参数：

     ```java
     int corePoolSize: 线程池核心线程大小
     int maximumPoolSize: 线程池最大线程数
     long keepAliveTime: 空闲线程存活时间
     TimeUnit unti: 空闲线程存活时间单位，一共有七种静态属性
     BlockingQueue<Runnable> workQueue: 工作队列
     ThreadFactory threadFactory: 线程工厂，主要用来创建线程（默认的工厂方法是：	        Executors.defaultThreadFactory()对线程进行安全检查并命名）
     RejectedExecutionHandler handler: 拒绝策略（默认是：ThreadPoolExecutor.abortPolicy	不执行并抛出异常）
     ```

3.   拒绝策略

     当工作队列中的任务已到达最大限制，并且线程池中的线程数量也达到最大限制，这是如果有新任务提交进来，就会执行拒绝策略

     jdk中提供了4种拒绝策略：

     1.   ThreadPoolExecutor.CallerRunsPolicy

          该策略下，在调用者线程中直接执行被拒绝任务的run方法，除非线程池已经shutdown，则直接抛弃任务

     2.   ThreadPoolExecutor.AboryPolicy

          该策略下，直接丢弃任务，并抛出RejectedExecutionException异常

     3.   ThreadPoolExecutor.DiscardPolicy

          该策略下，直接丢弃任务，什么都不做。

     4.   ThreadPoolExecutor.DiscardOlddestPolicy

          该策略下，抛弃进入队列最早的那个任务，然后尝试把这次拒绝的任务放入队列

          除此之外，还可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略

4.   任务放置的顺序过程

     任务调度是线程池的主要入口，当用户提交了一个任务，接下来这个任务将如何执行都是由这个阶段决定的，了解这部分就相当于了解了线程池的核心运行机制。

     首先，所有任务的调度都是由executor方法完成的，这部分完成的工作是：检查现在线程池的运行状态，运行线程数，运行策略，决定接下来执行的流程，是直接申请线程执行，或是缓冲到队列中执行，亦或是直接拒绝该策略。其执行过程如下：

     ```
     首先检测线程池运行状态，如果不是Running，则直接拒绝，线程池要保证在Running的状态下执行任务。
     如果workerCount < corePoolSize，则创建并启动一个线程来执行新提交的任务
     如果workerCount >= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中
     如果workerCount >= corePoolSize && workerCount < maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。
     如果workerCount >= maximumPoolSize，并且线程池内的阻塞队列已满，则根据拒绝策略来处理该任务，默认的处理方式是直接抛异常
     其执行流程如下图所示：
     ```

![未命名文件](%E5%A4%9A%E7%BA%BF%E7%A8%8B.assets/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6.png)

### 20.多线程几种状态及线程各个状态之间是如何切换的

| 运行状态   | 状态描述                                                     |
| ---------- | ------------------------------------------------------------ |
| RUNNING    | 能接受新提交的任务，并且也能处理阻塞队列中的任务             |
| SHUTDOWN   | 关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已经保存的任务 |
| STOP       | 不能接收新任务，也不处理队列中的任务，会中断正在处理的线程   |
| TIDYING    | 所有的任务已经终止，workerCount = 0                          |
| TERMINATED | 在terminated()方法执行后进入此状态                           |

![多线程状态](%E5%A4%9A%E7%BA%BF%E7%A8%8B.assets/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81-16389305623501.png)

### 21. 如何在方法栈中进行数据传递

1.   通过方法参数传递；
2.   通过共享变量；
3.   如果在同一个线程中，还可以使用ThreadLocal进行传递

### 22. ThreadLocal的底层实现及实现的数据结构

ThreadLocal类中有两个变量ThreadLocals和inheritableThreadLocals，二者都是ThreadLocals内部类ThreadLocalMap类型的变量，我们通过查看内部类ThreadLocalMap可以发现实际上它类似于一个HashMap，在默认情况下，每个线程中的这两个变量都为null：

```java
ThreadLocal.ThreadLocalMap threadLocals = null;
ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
```

只有当线程第一次调用ThreadLocal的set或者get方法的时候才会去创建它们

```java
public T get() {
	Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        ThreadLocalMap.Entry e = map.getEntry(this);
        if (e != null) {
            @SuppressWarnings("unchecked")
            T result = (T)e.value;
            return result;
        }
    }
    return setInitialValue();
}

ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}

```

除此之外，每个线程的本地变量不是存放在ThreadLocal实例中，而是放在调用线程的ThreadLocals变量里面。也就是说，ThreadLocal类型的本地变量是存放在具体的线程空间上，其本身相当于一个装在本地变量的工具壳，通过set方法将value添加到调用线程的threadLocals中，当调用线程调用get方法时候能够从它的threadLocals中取出变量，如果调用线程一直不终止，那么这个本地变量将会一直存放在他的threadLocals中，所以不适用本地变量的时候需要调用remove方法将threadLocals中删除不用的本地变量，防止出现内存泄漏。

```java
public void set(T value) {
    Thread t = Thread.currentThread();
	ThreadLocalMap map = getMap(t);
   	if (map != null) {
        map.set(this, value);
    } else {
        createMap(t, value);
    }
}

public void remove() {
    ThreadLocalMap m = getMap(Thread.currentThread());
    if (m != null) {
        m.remove();
    }
}
```

### 23. Synchroized是否是公平锁

不是

非公平锁比公平锁性能高，避免线程切换

### 24. 锁的四种状态及升级过程



### 25. CMS和G1的异同

CMS只对老年代进行收集，采用“**标记-清除**”算法，会出现内存碎片，但是可以设置；而G1使用了独立区域（Region）概念，G1从整体来看是基于“**标记-整理**”算法实现收集，从局部（两个Region）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片尤其是当Java堆非常大的时候，G1的优势更加明显，并且G1建立了可预测的停顿时间模型，可以直观的设定停顿时间的目标，减少每一次的垃圾收集时间，相比于CMS GC，G1未必能做到CMS在最好情况下的延时停顿，但是最差情况要好得多。

CMS：标记-清除

G1：标记-整理，分区，G1建立了可预测的停顿时间模型

### 26. G1什么时候引发FULL GC

1.   Evacuation的时候没有足够的to-space来存放晋升的对象
2.   并发处理过程完成之前空间耗尽

### 27. 除了CAS，原子类，syn，lock还有什么线程安全的方式

park()，信号量semaphore，blockingQueue，CycliBarrier

### 28. HashMap和HashTable的却别

1.   HashMap是非线程安全的，HashTable是线程安全的
2.   key，value都是对象，但是不能拥有重复key值，value值可以重复出现
3.   HashTable中，key和value都不允许出现null值
4.   HahsMap允许null值（key和value都可以），因为在HashMap中null可以作为键，而它对应的值可以有多个null
5.   HashTable是线程安全的，每个方法都要阻塞其他线程，所以HashTable性能较差，HashMap性能较好，使用更广
6.   HashTable继承了Dirtionary类，而HashMap继承的是AbstractMap类

### 29. CAS的ABA问题

加版本号，加时间戳

### 30. AQS

**状态变量state**

AQS中定义了一个状态变量state，它有一下两种使用方法：

1.   互斥锁：

     当AQS只实现为互斥锁的说，每次只要原子更新state的值从0变为1成功了就获取了锁，可重入是通过不断把state原子更新加1实现的。

2.   互斥锁+共享锁

     当AQS需要同时实现为互斥锁+共享锁的时候，低16为存储互斥锁的状态，高16位存储共享锁的状态，主要用于实现读写锁

     互斥锁是一种独占锁，每次只允许一个线程独占，且当一个线程独占时，其他线程将无法再获取互斥锁及共享锁，但是它自己可以获取共享锁。

     共享锁同时允许多个线程占有，只要有一个线程占有了共享锁，所有线程（包括自己）都将无法再获取互斥锁，但是可以获取共享锁

**AQS队列**

AQS中维护了一个队列，获取锁失败（非tryLock()）的线程都将进入这个队列中排队，等待释放后唤醒下一个排队的线程（互斥锁模式下）

**condition队列**

AQS中还有另外一个非常重要的内部类ConditionObject，它实现了Condition接口，主要用于实现条件锁。

AQS:

 	1. 互斥锁：
     	1. tryAcquire
     	2. tryRelease
 	2. 共享锁：
     	1. tryAcquireShared
     	2. tryReleaseShared

### 31. JUC包里的同步组件主要实现了AQS的那些主要方法

### 32. Volatile

1.   保证线程可见性
2.   防止指令重排序

-   可见性：
    -   
-   防止指令重排序：
    -   内存屏障：
        -   每个volatile写操作的前面插入一个StoreStore屏障
        -   每个volatile写操作的后面插入一个StoreLoad屏障
        -   每个volatile读操作的前面插入一个LoadLoad屏障
        -   每个volatile读操作的后面插入一个LoadStore屏障

### 33. ConcurrentHashMap底层原理

-   jdk1.7：

    -   内部主要是一个Segment，而每个数组的每一项又是一个HashEntry数组，元素都存在HashEntry数组里，因为每次锁定的是Segment对象，也就是整个HashEntry数组，所以又叫分段锁

-   jdk1.8：

    舍弃了分段锁的实现方式，元素都存在Node数组中，每次锁住的是一个Node对象，而不是某一段数组，所以支持的写的并发度更高

    再者引入了红黑树，在hash冲突严重时，读操作的效率更高









