### 缓存设计
    1. 缓存穿透
        缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，通常出于容错考虑，如果从存储层查不到数据则不写入缓存层。
        缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。
        造成缓存穿透的基本原因有两个：
            1. 代码问题或者数据出现问题
            2. 恶意攻击，爬虫等造成大量空命中
        缓存穿透问题解决方案：
        1. 缓存空对象：
            
        2. 布隆过滤器：
            对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，还可以用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器
            一般都能够过滤掉，不让请求再往后端发送，当布隆过滤器说某个值存在时，这个值可能不存在；当说不存在时，那就肯定不存在。

            布隆过滤器是一个大型的位数组和几个不一样的无偏hash函数，所谓无偏就是能够把元素的hash值算得比较均匀。
            向布隆过滤器中添加key时，会使用多个hash函数对key进行hash算得一个整数索引值然后对位数组长度进行取模运算得到一个位置，
            每个hash函数会算得一个不同的位置。再把位数组的这几个位置都置为1就完成了add操作。
            向布隆过滤器询问key是否存在时，跟add一样，也会把hash的几个位置都算出来，看看位数组中这几个位置是否都为1，只要有一个
            位为0，那么说明布隆过滤器中这个key不存在，如果都是1，这并不能说明这个key就一定存在，只是极有可能存在，因为这些位被置为1
            可能是因为其他的key存在所致。如果这个位数组比较稀疏，这个概率就会很大，如果这个位数组比较拥挤，这个概率就会降低。
            这种方法适用于数据命中不高，数据相对固定，实时性低(通常是数据集较大)的应用场景，代码维护较为复杂，但是缓存空间占用很少。
            
            布隆过滤器不能删除数据，如果要删除得重新初始化数据

    2. 缓存失效(击穿)
        由于大批量缓存再同一时间失效可能导致大量请求同时穿透缓存直达数据库，可能会造成数据库瞬间压力过大甚至挂掉，对于这种情况我们
        在批量增加缓存时就最好将这一批数据的缓存过期时间设置为一个时间段内的不同时间。
        
    3. 缓存雪崩
        缓存雪崩指的是缓存层支撑不住或宕掉后，流量会向奔逃的野牛一样，打向后端存储层
        由于缓存层承载着大量请求，有效地保护了存储层，但是如果缓存层由于某些原因不能提供服务(比如超大并发过来，缓存层支撑不住，
        或者由于缓存设计不好，类似大量请求访问bigkey，导致缓存能支撑的并发急剧下降)，于是大量请求都会打到存储层，存储层的调用量
        会暴增，造成存储层也会级联宕机的情况。
        
        预防和解决缓存雪崩问题，可以从一下三个方面进行着手：
        1. 保证缓存层服务高可用性，比如使用Redis Sentinel或Redis Cluster
        2. 依赖隔离组件为后端限流熔断并降级，比如使用Sentinel或Hystrix限流降级组件。
            比如服务降级，我们可以针对不同的数据采取不同的处理方式。当业务引用访问的是非核心数据(例如电商商品属性，用户信息等)时，
            暂时停止从缓存中查询这些数据，而是直接返回预定义的默认降级信息，空值或是错误提示信息；当业务应用访问的是核心数据(例如电商
            商品库存)时，任然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。
        3. 提前演练，在项目上线前，演练缓存层宕掉后，引用以及后端的负载情况以及可能出现的问题，再次基础上做一些预案设定。

    4. 热点缓存key重建优化
        使用"缓存+过期时间"的策略既可以加速数据读写，又保证数据的定期更新，这种模式基本能够满足绝大部分需求，但是有两个问题如果同时出现，
        可能就会对应用造成致命的危害：
            1. 当前key是一个热点key(例如一个热门的娱乐新闻)，并发量非常大。
            2. 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的sql，多次IO，多个依赖等
        在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃
        要解决这个问题主要就是要避免大量线程同时重建缓存。
        我们可以利用互斥锁来解决，此方法只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。
    
    5. 缓存与数据库双写不一致
        在大并发下，同时操作数据库与缓存会存在数据不一致性问题
        解决方案：
            1. 对于并发几率很小的数据(如个人维度的订单数据，用户数据等)，这种几乎不用考虑这个问题，很少会发生缓存不一致，
            可以给缓存数据加上过期时间，每隔一段时间出发读的主动更新即可。
            2. 就算并发很高，如果业务上能容忍短时间的缓存数据不一致(如商品名称，商品分类菜单等)，缓存加上过期时间依然可以解决
            大部分业务对于缓存的要求
            3. 如果不能容忍缓存数据不一致，可以通过加读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。
            4. 也可以用阿里开源的canal通过监听数据库的binlog日志及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。
        如果写多读多的情况又不能容忍缓存数据不一致，那就没必要加缓存了，可以直接操作数据库，放入缓存的数据应该是对实时性，一致性
        要求不是很高的数据，切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性。
 
### 键值设计
    1. key名设计
        1.可读性和可管理性
            以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名：表名:id
        2. 简洁性
            保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视
        3. 不要包含特殊字符
    
    2. value设计
        1. 拒绝bigkey(防止网卡流量，慢查询)
            在Redis中，一个字符串最大512MB，一个二级数据结构(例如hash，list，set，zset)可以存储大约40亿(2^32-1)
            个元素，但实际中如果下面两种清理，就会认为是bigkey
            1. 字符串类型：它的big体现在单个value值很大，一般人物超过10kb就是bigkey
            2. 非字符串类型：hash，列表，集合，有序集合，它们的big体现在元素个数太多
        一般来说，string类型控制在10kb以内，hash，list，set，zset元素个数不要超过5000
        非字符串的bigkey，不要使用del删除，使用hscan，sscan，zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题
        
        2. bigkey的危害:
            1. 导致redis阻塞
            2. 网络阻塞
            3. 过期删除
        
        3. bigkey的产生：
            一般来说，bigkey的产生都是由于程序设计不当，或者对于数据规模预料不清楚造成的，来看几个例子：
            1. 社交类：粉丝列表
            2. 统计类：例如按天存储某项功能或者网站的用户集合
            3. 缓存类：将数据从数据load出来序列化放到redis里
                第一：是不是有必要把所有字段都缓存
                第二：有没有相关关联的数据
        
        4. 如何优化bigkey：
            1. 拆
                big list: list1,list2,...listN
                big hash: 可以将数据分段存储，比如一个大的key，假设存了1百万的用户数据，可以拆分成200个key，每个
                            key下面存放5000个用户数据
                如果bigkey不可避免，也要思考一下要不要每次把所有元素都取出来(例如有时候仅仅需要hmget，而不是hgetall)，
                删除也是一样，尽量使用优雅的方式来处理
            
            2. 选择适合的数据类型
                例如：实体类型(要合理控制和使用数据结构，单也要注意节省内存和性能之间的平衡)
            
            2. 控制key的声明周期，redis不是垃圾桶
                使用expire设置过期时间(条件允许可以打散过期时间,防止集中过期)

### Redis过期策略
    1. 被动删除：当读写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key
    2. 主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key
    3. 当前已使用内存超过maxmemory限定时，触发主动清理策略
    
    主动清理策略在Redis 4.0之前一共实现了6中内存淘汰策略，在4.0之后，又增加了2中策略，总共8中：
        1. 针对设置了过期时间的key做处理：
            1. volatile-ttl: 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早
                过期的越先被删除
            2. volatile-random: 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除
            3. volatile-lru: 使用lru算法筛选设置了过期时间的键值对删除
            4. volatile-lfu: 使用lfu算法筛选设置了过期时间的键值对删除
        
        2. 针对所有的key做处理：
            5. allkeys-random: 从所有键值对中随机选择并删除数据
            6. allkeys-lru: 使用lru算法在所有数据中进行筛选删除
            7. allkeys-lfu: 使用lfu算法在所有数据中进行筛选删除
        3. 不处理：
            noeviction: 不会提出任何数据，拒绝所有写入操作并返回客户端错误信息，此时redis只响应读操作
        
    LRU算法(Least Recently Used, 最近最少使用)
        淘汰最近一段时间被访问次数最少的数据，以最近一次访问时间作为参考
    LFU算法(Least Frequently Used, 最不经常使用)
        淘汰最近一段时间被访问次数最少的数据，以次数作为参考

    当存在热点数据时，LRU的效率很好，但偶发性的，周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重，
    这时使用LFU更好点
    
