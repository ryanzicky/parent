### Lucence
    Lucence可以被认为是迄今为止最先进，性能最好的，功能最全的搜索引擎库(框架)
    Lucence缺点:
        1. 只能在Java项目中使用，并且要以jar包的方式直接集成在项目中
        2. 使用非常负责-创建索引和搜索索引代码繁杂
        3. 不支持集群环境-索引数据不同步(不支持大型项目)
        4. 索引数据如果太多就不行，索引库和应用所在同一个服务器，共同占用硬盘，公用空间少

### ES vs Solr比较
    1. ES vs Solr 检索速度
        单纯的对已有数据进行检索时，Solr更快
        当实时建立索引时，Solr会产生io阻塞，查询性能较差，Es具有明显的优势
        
        1. Solr利用Zookeeper进行分布式管理，Es自身带有分布式协调管理功能
        2. Solr支持更多格式的数据，比如JSON,XML,CSV,而Es仅支持json文件格式
        3. Solr在传统的搜索应用中表现好于Es，但在处理实时搜索应用时效率明显低于Es
        4. Solr是传统搜索应用的有力解决方案，但Es更适用于新兴的实时搜索应用

    2. Es vs 关系型数据库
        关系型数据库: 
            Database(数据库)，Table(表),Row(行),Column(列)
        Es:
            Index(索引),Type(类型),Document(文档),Field(字段)

### Lucence全文检索框架
    1. 什么是全文检索
        全文检索是指:
            1. 通过一个程序扫描文本中的每一个单词，针对单词建立索引，并保存该单词在文本中的位置，以及出现的次数
            2. 用户查询时，通过之前建立好的索引来查询，将索引中单词对应的文本位置，出现的次数返回给用户，因为有了
                具体文本的位置，所以就可以将具体内容读取出来了
    
    2. 分词原理之倒排索引
        
### Es中的核心概念
    1. 索引Index:
        一个索引就是一个拥有几分相似特征的文档的集合，比如说，可以有一个客户数据的索引，另一个产品目录的索引，还有一个
        订单数据的索引
        一个索引由一个名字来标识(必须全部是小写字母的)，并且当我们要对对应于这个索引中的文档进行索引，搜索，更新和删除的时候，
        都要用到这个名字
    
    2. 映射mapping
        Es中的mapping用来定义一个文档
        mapping是处理数据的方式和规则方面做一些限制，比如某个字段的数据类型，默认值，分词器，是否被索引等等，这些都是映射
        里可以设置的

    3. 字段Field
        相当于是数据表的字段|列

    4. 字段类型Type
        每一个字段都应该有一个对应的类型，例如: Text,Keyword,Byte等

    5. 文档Document
        一个文档是一个可被索引的基础信息单元，类似一条记录，文档以Json格式来表示

    6. 集群Cluster
        一个集群是由一个或多个节点组织在一起，它们共同持有整个的数据，并一起提供索引和搜索功能

    7. 节点Node
        一个节点是集群中的一个服务器，作为集群的一部分，它存储数据，参与集群的索引和搜索功能
        一个节点可以通过配置集群名称的方式来加入一个指定的集群，默认情况下，每个节点都会被安排加入到一个
        "elasticsearch"的集群中
        
    8. 分片和副本 shards & replicas
        1. 分片:
            1. 一个索引可以存储超出单个节点硬件限制的大量数据，比如，一个具有10亿文档的索引占据1TB的磁盘空间，
            而任一节点都没有这样大的磁盘空间，或者单个节点处理搜索请求，响应太慢
            2. 为了解决这个问题，Es提供了将索引划分成多份的能力，这些份就叫做分片
            3. 当创建一个索引的时候，可以指定想要的分片数量
            4. 每个分片本身就是一个功能完善并且独立的"索引"，这个"索引"可以被放置到集群中的任何节点上
            5. 分片很重要，主要有两方面的原因
                1. 允许水平分割/扩展你的内容容量
                2. 允许在分片智商进行分布式的，并行的操作，进而提高性能/吞吐量
            6. 至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全有Es管理的，对于作为用户来说，这些都是透明的
        2. 副本:
            1. 在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于某种原因小时了，
            这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Es允许你创建分片的一份或多份拷贝，这些拷贝
            叫做副本分片，或者直接叫副本
                · 副本之所以重要，有两个主要原因:
                    1. 在分片/节点失败的情况下，提供了高可用
                        注意到复制分片从不与原/主要分片置于同一节点上是非常重要的
                    2. 扩展搜索量/吞吐量,因为搜索可以在所有的副本上并行运行
                        每个索引可以被分成多个分片，一个索引有0个或者多个副本
                        一旦设置了副本，每个索引就有了主分片和副本分片，分片和副本的数量可以在索引创建的时候指定
                        在索引创建之后，可以在任何时候动态地概念副本的数量，但是不能改变分片的数量

### 分词器
    需要给Es单独安装IK分词插件
    
### Es数据管理
    Es是面向文档的，这意味着它可以存储整个对象或文档
    然而它不仅仅是存储，还会索引每个文档的内容使之可以被搜索

### DSL
    1. 叶子条件查询(单字段查询条件)
        1. 模糊匹配
            模糊匹配主要是针对文本类型的字段，文本类型的字段会对内容进行分词，对查询时，也会对搜索条件进行分词，然后通过
            倒排索引查找到匹配的数据，模糊匹配主要通过match等参数来实现
                · match:  通过match关键词模糊匹配条件内容
                · prefix: 前缀匹配
                · regexp: 通过正则表达式来匹配数据
            
        2. 精确匹配
            · term: 单个条件相等
            · terms: 单个字段属于某个值数组内的值
            · range: 字段属于某个范围内的值
            · exists: 某个字段的值是否存在
            · ids: 通过Id批量查询
            
        3. 组合条件查询(多条件查询)
        4. 连接查询(多文档合并查询)

    核心类型:
        字符串: string，string类型包含text和keyword
            text: 该类型用来索引长文本，在创建索引前会将这些文本进行分词，转化为词的组合，建立索引;允许es来检索这些词，
                text类型不能用来排序和聚合
            keyword: 该类型不能分词，可以用来检索过滤，排序和聚合，keyword类型不可用text进行分词模糊检索
            数值型: long，integer，short，byte，double，float
            日期型: date
            布尔型: boolean
        
### 对已存在的mapping映射进行修改
    1. 如果要推倒现有的映射，你得重新建立一个静态索引
    2. 然后把之前索引里的数据导入到新的索引里
    3. 删除原创建的索引
    4. 为新索引起个别名，为原索引名
    
### Es乐观并发控制
    在数据库领域中，有两种方法来确保并发更新，不会丢失数据
    1. 悲观并发控制
        数据加锁
    2. 乐观并发控制
        version控制
        7.0 之后seq_no 取代version
        version针对id
        seq_no针对整个索引

        乐观锁并发控制if_seq_no 和 if_primary_term意义
            version属于单个文档，seq_no属于整个index
            primary_term 表示文档所在主分片的编号

            primary_term 和seq_no一样都是整数，每当Primary Shard发生重新分配时，比如重启，Primary选举等，primary_term会递增1
            
            primary_term 主要是用来恢复数据时处理当多个文档的seq_no一样时的冲突，比如当一个shard宕机了，replica需要用到最新的数据，
            就会根据primary_term和seq_no这两个值来拿到最新的document
            

### 通过term 和match 查询数据时细节点以及数据类型keyword和text区别
    1. term查询keyword
        term不会分词，keyword也不分词，需要完全匹配
    2. term查询text
        因为text字段会分词，而term不分词，所有term查询的条件必须是term字段分词后的某一个
    3. match查询keyword
        match会被分词，而keyword不会被分词，match的需要跟keyword的完全匹配
    4. match查询text
        match分词，text也分词，只要match的分词结果和text的分词结果有相同的就匹配

### Es架构原理
    1. Es的节点类型
        Es主要分成两类节点，一类是Master，一类是DataNode
        
        Master节点:
            Master节点主要负责:
                1. 管理索引(创建索引，删除索引)，分配分片
                2. 维护元数据
                3. 管理集群节点状态
                4. 不负责数据写入和查询，比较轻量级
            一个Es集群中，只有一个Master节点，在生产环境中，内存可以相对小一些，但机器要稳定
        
        DataNode节点:
            在Es集群中，会有N个DataNode节点，DataNode节点主要负责: 数据写入，数据检索，大部分Es的压力都在DataNode节点上，
            在生产环境中，内存最好配置大一些

    2. 分片和副本机制
        1. 分片(Shard)
            Es是一个分布式的搜索引擎，索引的数据也是分成若干部分，分布在不同的服务器节点中
            分布在不同服务器节点中的索引数据，就是分片，Es会自动管理分片，如果发现分片分布不均衡，就会自动迁移
            一个索引由多个分片组成，而分片是分布在不同的服务器上的

        2. 副本
            为了对Es的分片进行容错，假设某个节点不可用，会导致整个索引库都将不可用。所以，需要对分片进行副本容错。
            每一个分片都会有对应的副本
            
            在Es中，默认创建的索引为1个分片，每个分片有1个主分片和1个副本分片
            每个分片都会有一个Primary Shard，也会有若干个Replica Shard(副本分片)
            Primary Shard和Replica Shard不在同一个节点上

### Es重要工作流程
    1. Es文档写入原理
        1. client 选择任意一个DataNode节点发送请求，例如:node2, 此时node2就成为一个coordinating node(协调节点)
        2. 计算得到文档要写入的分片
        3. coordinating node会进行路由，将请求转发给到其他的DataNode(对应某个Primary Shard)
            假设primary shard 在node1， replica shard 在node2
        4. node1节点上的primary shard 处理请求，写入数据到索引库中，并将数据同步到replica shard
        5. primary shard 和 replica shard 都保存好了文档，返回client

    2. Es检索原理
        1. client选择一个DataNode发送请求，例如: node2，此时，node2就成为了一个coordinating node(协调节点)
        2. coordinating node 将查询请求广播到每一个数据节点，这些数据节点的分片会处理该查询请求
        3. 每个分片进行数据查询，将符合条件的数据放在一个优先队列中，并将这些数据的文档ID，节点信息，分片信息返回给协调节点
            协调节点将所有的结果进行汇总，并进行全局排序
        4. 协调节点向包含这些文档ID的分片发送get请求，对应的分片经文档数据返回给协调节点，最后协调节点将数据返回给client

### Es准实时索引实现
    1. 溢写到文件系统缓存
        当数据写入到Es分片时，会首先写入到内存中，然后通过内存的buffer生成一个segment，并刷到文件系统缓存中，数据可以被检索(
        注意不是直接刷到磁盘)，Es中默认1s，refresh一次
    2. 写translog保障容错
        在写入到内存中的同时，也会记录translog日志，在refresh期间出现异常，会根据translog来进行数据恢复
        等到文件系统缓存中的segment数据都刷到磁盘中，清空translog文件
    3. flush到磁盘
        Es默认每隔30分钟会将文件系统缓存的数据刷入到磁盘
    4. segment 合并
        Segment太多时，Es定期会将多个Segment 合并成为大的Segment，检索索引查询时IO开销，此阶段Es会真正的物理删除(之前执行过的delete的数据)
        
### 手工控制搜索结果精准度
    
### Es集群状态
    green: 每个索引的primary shard 和 replica shard 都是active状态的
    yellow: 每个索引的primary shard 都是active 状态的，但是部分replica shard 不是active 状态，处于不可用状态
    red: 不是所有索引的primary shard 都是active 状态的，部分索引有数据丢失

    不同节点介绍:
        主节点: node.master: true
        数据节点: node.data: true

        1. 客户端节点: 
            当主节点和数据节点配置都设置为false的时候，该节点只能处理路由请求，处理搜索，分发索引操作等，从本质上来说
            该客户端节点表现为智能负载平衡器
            独立的客户端节点在一个比较大的集群中是非常有用的，他协调主节点和数据节点，客户端节点加入集群可以得到集群的状态，
            根据集群的状态可以直接路由请求
        2. 数据节点:
            数据节点主要是存储索引数据的节点，主要对文档进行增删改查操作，聚合操作等，数据节点对cpu，内存，io要求较高，
            在优化的时候需要监控数据节点的状态，当资源不够的时候，需要在集群中添加新的节点
        3. 主节点:
            主节点的主要职责是和集群操作相关的内容，如创建或删除索引，跟踪哪些节点是集群的一部分，并决定哪些分片分配给相关的节点，
            稳定的主节点对集群的健康是非常重要的，默认情况下任何一个集群中的节点都有可能被选为主节点，索引数据和搜索查询等操作会
            占用大量的cpu，内存，io资源，为了确保一个集群的稳定，分离主节点和数据节点是一个比较好的选择。

### Es文档分支_score计算底层原理
    1. boolean model
        根据用户的query条件，先过滤出包含指定term的doc
    2. relevance score 算法，简单来说，就是计算出，一个索引中的文本，与搜索文本，他们之间的关联匹配程度
        Es使用的是 term frequency/inverse document frequency 算法，简称为 TF/IDF 算法

        Term frequency: 搜索文本中的各个词条在field文本中出现了多少次，出现次数越多，就越相关
        Inverse document frequency: 搜索文本中的各个词条在整个索引的所有文档中出现了多少次，出现的次数越多，就越不相关
        
        Fielf-length norm: field 长度，field 越长，相关度就越弱
    3. vector space model
        多个 term 对一个doc的总分数
        hello world --> es 会根据hello world 在所有doc中的评分情况，计算出一个query vector，query向量
        hello 这个 term， 给的基于所有doc的一个评分就是2
        world 这个 term， 给的基于所有doc的一个评分就是5
        [2，5]

### 分词器工作流程
    默认分词器 standard
    ik 分词器
        ik 热更新:
            1. 每次添加完，都要重启es才能生效，非常麻烦
            2. es是分布式的，可能有数百个节点，不能每次都一个一个节点上去修改
            
### 聚合搜索
     1. bucket 和 metric
        bucket 是一个聚合搜索时的数据分组
        metric 是对一个bucket数据执行的统计分析

### es生产集群部署之针对生产集群的脑裂问题专门定制的重要参数
    集群脑裂是什么?
        所谓脑裂问题，就是同一个集群中的不同节点，对于集群的状态有了不一样的理解，比如集群中存在两个master
        如果因为网络的故障，导致一个集群被划分成了两片，每片都有多个node，以及一个master，那么集群中就出现了两个master了
        但是因为master是集群中非常重要的一个角色，主宰了集群状态的维护，以及shard的分配，因此两个master，可能会导致破坏数据

    集群中master节点的数量至少3台，三台主节点通过再elasticsearch.yml中配置discovery.zen.minimum_master_nodes: 2
    可以避免脑裂问题的产生

### 数据建模
    普通的数组数据在Es中会被扁平化处理，处理方式如下: (如果字段需要分词，会将分词数据保存在对应的字段位置，当然应该是一个倒排索引)
    那么nested object数据类型Es在保存的时候不会有扁平化处理

### 分页搜索
    使用from和size方式，查询在1w-5w条数据以内是ok的，但如果数据比较多的时候，会出现性能问题，Es做了一个限制，不允许查询的是
    10000条以后的数据，如果要查询1w条以后的数据，需要使用Es提供的scroll游标来查询
    在进行大量分页时，每次分页都需要将要查询的数据进行重新排序，这样非常浪费性能，使用scroll是将要用的数据一次性排序好，然后分批取出，
    性能要比from+size好得多，使用scroll查询后，排序后的数据会保持一定的时间，后续的分页查询都要从该快照取数据即可
        
### search template
    
### suggest search(completion suggest)
    suggest search(completion suggest): 就是建议搜索或称为搜索建议，也可以叫做自动完成-auto completion，类似百度中的搜索联想提示功能
    Es实现suggest的时候，性能非常高，其构建的不是倒排索引，也不是正排索引，就是纯的用于进行前缀搜索的一种特殊的数据结构，而且会全部放在
    内存中，所以suggest search 进行的前缀搜索提示，性能非常高
    需要suggest的时候，必须在定义index时，为其mapping指定开启suggest

### geo point - 地理位置搜索和聚合分析
    Es支持地理位置的搜索和聚合分析，可实现在指定区域内搜索数据，搜索指定地点附近的数据，聚合分析指定地点附近的护具等操作
    Es中如果使用地理位置搜索的话，必须提供一个特殊的字段类型，GEO - geo_point，地理位置的坐标点
    
### Beats
    Beats是一个开源的数据发送器，我们可以把Beats作为一种代理安装在我们的服务器上，这样就可以比较方便地将数据发送到Es或者Logstash中，
    Elastic Stack提供了多种类型的Beats组件

    Beats Logstash Elasticsearch Kibana
    Beats 可以直接将数据发送到Elasticsearch或者发送到logstash，基于Logstash可以进一步地对数据进行处理，然后将处理后的数据存入到Elasticsearch，
    最后使用Kibana进行数据可视化
    
    FileBeat简介:
        FileBeat专门用于转发和手机日志数据的轻量级采集工具，它可以为作为代理安装在服务器上，FileBeat监视指定路径的日志文件，收集日志数据，并
        将收集到的日志转发到Elasticsearch或者Logstash
    
        FileBeat工作原理:
            启动FileBeat时，会启动一个或者多个输入(Input)，这些Input监控指定的日志数据位置，FileBeat会针对每一个文件启动一个Harvester(收割机)。
            Harvester读取每一个文件的日志，将新的日志发送到Libbeat，Libbeat将数据收集到一起，并将数据发送给输出(Output).

            FileBeat主要由input和harvesters(收割机)组成，这两个组件协同工作，并将数据发送到指定的输出
            1. input和harvester
                inputs(输入)
                    input是负责管理Harvester和查找所有要读取的文件的组件
                    如果输入类型是log，input组件会查找磁盘上与路径描述的所有文件，并为每个文件启动一个Harvester，每个输入都独立地运行
                Harvester
                    Harvester负责读取单个文件的内容，它负责打开/关闭文件，并逐行读取每个文件的内容，将读取到的内容发送给输出
                    每个文件都会启动一个Harvester
                    Harvester运行时，文件将处于打开状态，如果文件在读取时，被移除或者重命名，FileBeat将继续读取该文件

            2. FileBeat如何保持文件状态
                FileBeat保存每个文件的状态，并定时将状态信息保存在磁盘的[注册表]文件中
                该状态记录Harvester读取的最后一次偏移量，并确保发送所有的日志数据
                如果输出(Es或Logstash)可用时，继续读取文件发送数据
                在运行FileBeat时，每个inout的状态信息也会保存在内存中，重新启动FileBeat时，会从[注册表]文件中读取数据来重新构建状态

### Logstash
    Logstash是一个开源的数据采集引擎，它可以动态地将不同来源的数据统一采集，并按照指定的数据格式进行处理后，将数据加载到其他的目的地。最开始，
    Logstash主要是针对日志采集，但后来Logstash开发了大量的插件，所以，它可以做更多的海量数据的采集
    它可以处理各种类型的日志数据，例如: Apache 的web log，Java的log4j日志数据，或者是系统，网络，防火墙的日志等等，它也可以很容易的和
    ElasticStack的Beats组件整合，也可以很方便的和关系型数据库，NoSql数据库，MQ等整合

    对比FileBeat
        logstash是jvm跑的，资源消耗比较大
        而FileBeat是基于golang编写的，功能较少但资源消耗也比较小，更轻量级logstash和filebeat都有日志收集功能，filebeat更轻量，占用资源更少
        logstash具有filter功能，能过滤分析日志
        一般结构都是filebeat采集日志，然后发送到消息队列，redis，MQ中然后logstash去获取，利用filter功能过滤分析，然后存储到elasticsearch中
        FileBeat和Logstash配合，实现背压机制

        
            
    
        

        

            
            
    